[Skip to main content](#__docusaurus_skipToContent_fallback)

**Help us build the JS tools that power AI apps at companies like Replit, Uber, LinkedIn, GitLab, and more. [Join our team!](https://jobs.ashbyhq.com/langchain/05efa205-8560-43fd-bfcc-3f7697561cfb?utm_source=https%3A%2F%2Fjs.langchain.com%2F&utm_campaign=langchainjs_docs)**

[![ðŸ¦œï¸ðŸ”— Langchain](/img/brand/wordmark.png)![ðŸ¦œï¸ðŸ”— Langchain](/img/brand/wordmark-dark.png)](/)[Integrations](/docs/integrations/platforms/)[API Reference](https://v03.api.js.langchain.com)

More

* [People](/docs/people/)
* [Community](/docs/community)
* [Error reference](/docs/troubleshooting/errors)
* [External guides](/docs/additional_resources/tutorials)
* [Contributing](/docs/contributing)

v0.3

* [v0.3](/docs/introduction)
* [v0.2](https://js.langchain.com/v0.2/docs/introduction)
* [v0.1](https://js.langchain.com/v0.1/docs/get_started/introduction)

ðŸ¦œðŸ”—

* [LangSmith](https://smith.langchain.com)
* [LangSmith Docs](https://docs.smith.langchain.com)
* [LangChain Hub](https://smith.langchain.com/hub)
* [LangServe](https://github.com/langchain-ai/langserve)
* [Python Docs](https://python.langchain.com/)

[Chat](https://chatjs.langchain.com)

Search

* [Introduction](/docs/introduction)
* [Tutorials](/docs/tutorials/)

  + [Build a Question Answering application over a Graph Database](/docs/tutorials/graph)
  + [Tutorials](/docs/tutorials/)
  + [Build a simple LLM application with chat models and prompt templates](/docs/tutorials/llm_chain)
  + [Build a Chatbot](/docs/tutorials/chatbot)
  + [Build a Retrieval Augmented Generation (RAG) App: Part 2](/docs/tutorials/qa_chat_history)
  + [Build an Extraction Chain](/docs/tutorials/extraction)
  + [Tagging](/docs/tutorials/classification)
  + [Build a Retrieval Augmented Generation (RAG) App: Part 1](/docs/tutorials/rag)
  + [Build a semantic search engine](/docs/tutorials/retrievers)
  + [Build a Question/Answering system over SQL data](/docs/tutorials/sql_qa)
  + [Summarize Text](/docs/tutorials/summarization)
* [How-to guides](/docs/how_to/)

  + [How-to guides](/docs/how_to/)
  + [How to add memory to chatbots](/docs/how_to/chatbots_memory)
  + [How to use example selectors](/docs/how_to/example_selectors)
  + [Installation](/docs/how_to/installation)
  + [How to stream responses from an LLM](/docs/how_to/streaming_llm)
  + [How to stream chat model responses](/docs/how_to/chat_streaming)
  + [How to embed text data](/docs/how_to/embed_text)
  + [How to use few shot examples in chat models](/docs/how_to/few_shot_examples_chat)
  + [How to cache model responses](/docs/how_to/llm_caching)
  + [How to cache chat model responses](/docs/how_to/chat_model_caching)
  + [Richer outputs](/docs/how_to/custom_llm)
  + [How to use few shot examples](/docs/how_to/few_shot_examples)
  + [How to use output parsers to parse an LLM response into structured format](/docs/how_to/output_parser_structured)
  + [How to return structured data from a model](/docs/how_to/structured_output)
  + [How to add ad-hoc tool calling capability to LLMs and Chat Models](/docs/how_to/tools_prompting)
  + [Richer outputs](/docs/how_to/custom_chat)
  + [How to do per-user retrieval](/docs/how_to/qa_per_user)
  + [How to track token usage](/docs/how_to/chat_token_usage_tracking)
  + [How to track token usage](/docs/how_to/llm_token_usage_tracking)
  + [How to pass through arguments from one step to the next](/docs/how_to/passthrough)
  + [How to compose prompts together](/docs/how_to/prompts_composition)
  + [How to use legacy LangChain Agents (AgentExecutor)](/docs/how_to/agent_executor)
  + [How to add values to a chain's state](/docs/how_to/assign)
  + [How to attach runtime arguments to a Runnable](/docs/how_to/binding)
  + [How to cache embedding results](/docs/how_to/caching_embeddings)
  + [How to attach callbacks to a module](/docs/how_to/callbacks_attach)
  + [How to pass callbacks into a module constructor](/docs/how_to/callbacks_constructor)
  + [How to dispatch custom callback events](/docs/how_to/callbacks_custom_events)
  + [How to pass callbacks in at runtime](/docs/how_to/callbacks_runtime)
  + [How to await callbacks in serverless environments](/docs/how_to/callbacks_serverless)
  + [How to cancel execution](/docs/how_to/cancel_execution)
  + [How to split by character](/docs/how_to/character_text_splitter)
  + [How to init any model in one line](/docs/how_to/chat_models_universal_init)
  + [How to do retrieval](/docs/how_to/chatbots_retrieval)
  + [How to add tools to chatbots](/docs/how_to/chatbots_tools)
  + [How to split code](/docs/how_to/code_splitter)
  + [How to do retrieval with contextual compression](/docs/how_to/contextual_compression)
  + [How to convert Runnables to Tools](/docs/how_to/convert_runnable_to_tool)
  + [How to create custom callback handlers](/docs/how_to/custom_callbacks)
  + [How to write a custom retriever class](/docs/how_to/custom_retriever)
  + [How to create Tools](/docs/how_to/custom_tools)
  + [How to debug your LLM apps](/docs/how_to/debugging)
  + [How to load CSV data](/docs/how_to/document_loader_csv)
  + [How to write a custom document loader](/docs/how_to/document_loader_custom)
  + [How to load data from a directory](/docs/how_to/document_loader_directory)
  + [How to load HTML](/docs/how_to/document_loader_html)
  + [How to load Markdown](/docs/how_to/document_loader_markdown)
  + [How to load PDF files](/docs/how_to/document_loader_pdf)
  + [How to load JSON data](/docs/how_to/document_loaders_json)
  + [How to combine results from multiple retrievers](/docs/how_to/ensemble_retriever)
  + [How to select examples from a LangSmith dataset](/docs/how_to/example_selectors_langsmith)
  + [How to select examples by length](/docs/how_to/example_selectors_length_based)
  + [How to select examples by similarity](/docs/how_to/example_selectors_similarity)
  + [How to use reference examples](/docs/how_to/extraction_examples)
  + [How to handle long text](/docs/how_to/extraction_long_text)
  + [How to do extraction without using function calling](/docs/how_to/extraction_parse)
  + [Fallbacks](/docs/how_to/fallbacks)
  + [Few Shot Prompt Templates](/docs/how_to/few_shot)
  + [How to filter messages](/docs/how_to/filter_messages)
  + [How to run custom functions](/docs/how_to/functions)
  + [How to build an LLM generated UI](/docs/how_to/generative_ui)
  + [How to construct knowledge graphs](/docs/how_to/graph_constructing)
  + [How to map values to a database](/docs/how_to/graph_mapping)
  + [How to improve results with prompting](/docs/how_to/graph_prompting)
  + [How to add a semantic layer over the database](/docs/how_to/graph_semantic)
  + [How to reindex data to keep your vectorstore in-sync with the underlying data source](/docs/how_to/indexing)
  + [LangChain Expression Language Cheatsheet](/docs/how_to/lcel_cheatsheet)
  + [How to get log probabilities](/docs/how_to/logprobs)
  + [How to merge consecutive messages of the same type](/docs/how_to/merge_message_runs)
  + [How to add message history](/docs/how_to/message_history)
  + [How to migrate from legacy LangChain agents to LangGraph](/docs/how_to/migrate_agent)
  + [How to generate multiple embeddings per document](/docs/how_to/multi_vector)
  + [How to pass multimodal data directly to models](/docs/how_to/multimodal_inputs)
  + [How to use multimodal prompts](/docs/how_to/multimodal_prompts)
  + [How to generate multiple queries to retrieve data for](/docs/how_to/multiple_queries)
  + [How to try to fix errors in output parsing](/docs/how_to/output_parser_fixing)
  + [How to parse JSON output](/docs/how_to/output_parser_json)
  + [How to parse XML output](/docs/how_to/output_parser_xml)
  + [How to invoke runnables in parallel](/docs/how_to/parallel)
  + [How to retrieve the whole document for a chunk](/docs/how_to/parent_document_retriever)
  + [How to partially format prompt templates](/docs/how_to/prompts_partial)
  + [How to add chat history](/docs/how_to/qa_chat_history_how_to)
  + [How to return citations](/docs/how_to/qa_citations)
  + [How to return sources](/docs/how_to/qa_sources)
  + [How to stream from a question-answering chain](/docs/how_to/qa_streaming)
  + [How to construct filters](/docs/how_to/query_constructing_filters)
  + [How to add examples to the prompt](/docs/how_to/query_few_shot)
  + [How to deal with high cardinality categorical variables](/docs/how_to/query_high_cardinality)
  + [How to handle multiple queries](/docs/how_to/query_multiple_queries)
  + [How to handle multiple retrievers](/docs/how_to/query_multiple_retrievers)
  + [How to handle cases where no queries are generated](/docs/how_to/query_no_queries)
  + [How to recursively split text by characters](/docs/how_to/recursive_text_splitter)
  + [How to reduce retrieval latency](/docs/how_to/reduce_retrieval_latency)
  + [How to route execution within a chain](/docs/how_to/routing)
  + [How to do "self-querying" retrieval](/docs/how_to/self_query)
  + [How to chain runnables](/docs/how_to/sequence)
  + [How to split text by tokens](/docs/how_to/split_by_token)
  + [How to deal with large databases](/docs/how_to/sql_large_db)
  + [How to use prompting to improve results](/docs/how_to/sql_prompting)
  + [How to do query validation](/docs/how_to/sql_query_checking)
  + [How to stream agent data to the client](/docs/how_to/stream_agent_client)
  + [How to stream structured output to the client](/docs/how_to/stream_tool_client)
  + [How to stream](/docs/how_to/streaming)
  + [How to create a time-weighted retriever](/docs/how_to/time_weighted_vectorstore)
  + [How to return artifacts from a tool](/docs/how_to/tool_artifacts)
  + [How to use chat models to call tools](/docs/how_to/tool_calling)
  + [How to disable parallel tool calling](/docs/how_to/tool_calling_parallel)
  + [How to call tools with multimodal data](/docs/how_to/tool_calls_multimodal)
  + [How to force tool calling behavior](/docs/how_to/tool_choice)
  + [How to access the RunnableConfig from a tool](/docs/how_to/tool_configure)
  + [How to pass tool outputs to chat models](/docs/how_to/tool_results_pass_to_model)
  + [How to pass run time values to tools](/docs/how_to/tool_runtime)
  + [How to stream events from a tool](/docs/how_to/tool_stream_events)
  + [How to stream tool calls](/docs/how_to/tool_streaming)
  + [How to use LangChain tools](/docs/how_to/tools_builtin)
  + [How to handle tool errors](/docs/how_to/tools_error)
  + [How to use few-shot prompting with tool calling](/docs/how_to/tools_few_shot)
  + [How to trim messages](/docs/how_to/trim_messages)
  + [How use a vector store to retrieve data](/docs/how_to/vectorstore_retriever)
  + [How to create and query vector stores](/docs/how_to/vectorstores)
* [Conceptual Guide](/docs/concepts/)

  + [Agents](/docs/concepts/agents)
  + [Architecture](/docs/concepts/architecture)
  + [Callbacks](/docs/concepts/callbacks)
  + [Chat history](/docs/concepts/chat_history)
  + [Chat models](/docs/concepts/chat_models)
  + [Document loaders](/docs/concepts/document_loaders)
  + [Embedding models](/docs/concepts/embedding_models)
  + [Evaluation](/docs/concepts/evaluation)
  + [Example selectors](/docs/concepts/example_selectors)
  + [Few-shot prompting](/docs/concepts/few_shot_prompting)
  + [Conceptual guide](/docs/concepts/)
  + [Key-value stores](/docs/concepts/key_value_stores)
  + [LangChain Expression Language (LCEL)](/docs/concepts/lcel)
  + [Messages](/docs/concepts/messages)
  + [Multimodality](/docs/concepts/multimodality)
  + [Output parsers](/docs/concepts/output_parsers)
  + [Prompt Templates](/docs/concepts/prompt_templates)
  + [Retrieval augmented generation (rag)](/docs/concepts/rag)
  + [Retrieval](/docs/concepts/retrieval)
  + [Retrievers](/docs/concepts/retrievers)
  + [Runnable interface](/docs/concepts/runnables)
  + [Streaming](/docs/concepts/streaming)
  + [Structured outputs](/docs/concepts/structured_outputs)
  + [t](/docs/concepts/t)
  + [String-in, string-out llms](/docs/concepts/text_llms)
  + [Text splitters](/docs/concepts/text_splitters)
  + [Tokens](/docs/concepts/tokens)
  + [Tool calling](/docs/concepts/tool_calling)
  + [Tools](/docs/concepts/tools)
  + [Tracing](/docs/concepts/tracing)
  + [Vector stores](/docs/concepts/vectorstores)
  + [Why LangChain?](/docs/concepts/why_langchain)
* Ecosystem

  + [ðŸ¦œðŸ› ï¸ LangSmith](https://docs.smith.langchain.com/)
  + [ðŸ¦œðŸ•¸ï¸ LangGraph.js](https://langchain-ai.github.io/langgraphjs/)
* Versions

  + [v0.3](/docs/versions/v0_3/)
  + [v0.2](/docs/versions/v0_2/)
  + [Migrating from v0.0 memory](/docs/versions/migrating_memory/)

    - [How to migrate to LangGraph memory](/docs/versions/migrating_memory/)
    - [How to use BaseChatMessageHistory with LangGraph](/docs/versions/migrating_memory/chat_history)
    - [Migrating off ConversationTokenBufferMemory](/docs/versions/migrating_memory/conversation_buffer_window_memory)
    - [Migrating off ConversationSummaryMemory or ConversationSummaryBufferMemory](/docs/versions/migrating_memory/conversation_summary_memory)
  + [Release Policy](/docs/versions/release_policy)
* [Security](/docs/security)

* [How-to guides](/docs/how_to/)
* How to select examples from a LangSmith dataset

On this page

# How to select examples from a LangSmith dataset

Prerequisites

* [Chat models](/docs/concepts/chat_models)
* [Few-shot-prompting](/docs/concepts/few_shot_prompting)
* [LangSmith](/docs/concepts/#langsmith)

Compatibility

* `langsmith` >= 0.1.43

LangSmith datasets have built-in support for similarity search, making
them a great tool for building and querying few-shot examples.

In this guide weâ€™ll see how to use an indexed LangSmith dataset as a
few-shot example selector.

## Setup[â€‹](#setup "Direct link to Setup")

Before getting started make sure youâ€™ve [created a LangSmith
account](https://smith.langchain.com/) and set your credentials:

```
process.env.LANGSMITH_API_KEY = "your-api-key";
process.env.LANGSMITH_TRACING = "true";

```

Weâ€™ll need to install the `langsmith` SDK. In this example weâ€™ll also
make use of `langchain` and `@langchain/anthropic`:

* npm
* yarn
* pnpm

```
npm i langsmith langchain @langchain/anthropic @langchain/core zod zod-to-json-schema

```

```
yarn add langsmith langchain @langchain/anthropic @langchain/core zod zod-to-json-schema

```

```
pnpm add langsmith langchain @langchain/anthropic @langchain/core zod zod-to-json-schema

```

Now weâ€™ll clone a public dataset and turn on indexing for the dataset.
We can also turn on indexing via the [LangSmith
UI](https://docs.smith.langchain.com/how_to_guides/datasets/index_datasets_for_dynamic_few_shot_example_selection).

Weâ€™ll create a clone the [Multiverse math few shot example
dataset](https://blog.langchain.dev/few-shot-prompting-to-improve-tool-calling-performance/).

This enables searching over the dataset, and will make sure that anytime
we update/add examples they are also indexed.

The first step to creating a clone is to read the JSON file containing
the examples and convert them to the format expected by LangSmith for
creating examples:

```
import { Client as LangSmithClient } from "langsmith";
import { z } from "zod";
import { zodToJsonSchema } from "zod-to-json-schema";
import fs from "fs/promises";

// Read the example dataset and convert to the format expected by the LangSmith API
// for creating new examples
const examplesJson = JSON.parse(
  await fs.readFile("../../data/ls_few_shot_example_dataset.json", "utf-8")
);

let inputs: Record<string, any>[] = [];
let outputs: Record<string, any>[] = [];
let metadata: Record<string, any>[] = [];

examplesJson.forEach((ex) => {
  inputs.push(ex.inputs);
  outputs.push(ex.outputs);
  metadata.push(ex.metadata);
});

// Define our input schema as this is required for indexing
const inputsSchema = zodToJsonSchema(
  z.object({
    input: z.string(),
    system: z.boolean().optional(),
  })
);

const lsClient = new LangSmithClient();

await lsClient.deleteDataset({
  datasetName: "multiverse-math-examples-for-few-shot-example",
});

const dataset = await lsClient.createDataset(
  "multiverse-math-examples-for-few-shot-example",
  {
    inputsSchema,
  }
);

const createdExamples = await lsClient.createExamples({
  inputs,
  outputs,
  metadata,
  datasetId: dataset.id,
});

```

```
await lsClient.indexDataset({ datasetId: dataset.id });

```

Once the dataset is indexed, we can search for similar examples like so:

```
const examples = await lsClient.similarExamples(
  { input: "whats the negation of the negation of the negation of 3" },
  dataset.id,
  3
);
console.log(examples.length);

```

```
3

```

```
console.log(examples[0].inputs.input);

```

```
evaluate the negation of -100

```

For this dataset the outputs are an entire chat history:

```
console.log(examples[1].outputs.output);

```

```
[
  {
    id: 'cbe7ed83-86e1-4e46-89de-6646f8b55cef',
    type: 'system',
    content: 'You are requested to solve math questions in an alternate mathematical universe. The operations have been altered to yield different results than expected. Do not guess the answer or rely on your  innate knowledge of math. Use the provided tools to answer the question. While associativity and commutativity apply, distributivity does not. Answer the question using the fewest possible tools. Only include the numeric response without any clarifications.',
    additional_kwargs: {},
    response_metadata: {}
  },
  {
    id: '04946246-09a8-4465-be95-037efd7dae55',
    type: 'human',
    content: 'if one gazoink is 4 badoinks, each of which is 6 foos, each of wich is 3 bars - how many bars in 3 gazoinks?',
    example: false,
    additional_kwargs: {},
    response_metadata: {}
  },
  {
    id: 'run-d6f0954e-b21b-4ea8-ad98-0ee64cfc824e-0',
    type: 'ai',
    content: [ [Object] ],
    example: false,
    tool_calls: [ [Object] ],
    usage_metadata: { input_tokens: 916, total_tokens: 984, output_tokens: 68 },
    additional_kwargs: {},
    response_metadata: {
      id: 'msg_01MBWxgouUBzomwTvXhomGVq',
      model: 'claude-3-sonnet-20240229',
      usage: [Object],
      stop_reason: 'tool_use',
      stop_sequence: null
    },
    invalid_tool_calls: []
  },
  {
    id: '3d4c72c4-f009-48ce-b739-1d3f28ee4803',
    name: 'multiply',
    type: 'tool',
    content: '13.2',
    tool_call_id: 'toolu_016RjRHSEyDZRqKhGrb8uvjJ',
    additional_kwargs: {},
    response_metadata: {}
  },
  {
    id: 'run-26dd7e83-f5fb-4c70-8ba1-271300ffeb25-0',
    type: 'ai',
    content: [ [Object] ],
    example: false,
    tool_calls: [ [Object] ],
    usage_metadata: { input_tokens: 999, total_tokens: 1070, output_tokens: 71 },
    additional_kwargs: {},
    response_metadata: {
      id: 'msg_01VTFvtCxtR3rN58hCmjt2oH',
      model: 'claude-3-sonnet-20240229',
      usage: [Object],
      stop_reason: 'tool_use',
      stop_sequence: null
    },
    invalid_tool_calls: []
  },
  {
    id: 'ca4e0317-7b3a-4638-933c-1efd98bc4fda',
    name: 'multiply',
    type: 'tool',
    content: '87.12',
    tool_call_id: 'toolu_01PqvszxiuXrVJ9bwgTWaH3q',
    additional_kwargs: {},
    response_metadata: {}
  },
  {
    id: 'run-007794ac-3590-4b9e-b678-008f02e40042-0',
    type: 'ai',
    content: [ [Object] ],
    example: false,
    tool_calls: [ [Object] ],
    usage_metadata: { input_tokens: 1084, total_tokens: 1155, output_tokens: 71 },
    additional_kwargs: {},
    response_metadata: {
      id: 'msg_017BEkSqmTsmtJaTxAzfRMEh',
      model: 'claude-3-sonnet-20240229',
      usage: [Object],
      stop_reason: 'tool_use',
      stop_sequence: null
    },
    invalid_tool_calls: []
  },
  {
    id: '7f58c121-6f21-4c7b-ba38-aa820e274ff8',
    name: 'multiply',
    type: 'tool',
    content: '287.496',
    tool_call_id: 'toolu_01LU3RqRUXZRLRoJ2AZNmPed',
    additional_kwargs: {},
    response_metadata: {}
  },
  {
    id: 'run-51e35afb-7ec6-4738-93e2-92f80b5c9377-0',
    type: 'ai',
    content: '287.496',
    example: false,
    tool_calls: [],
    usage_metadata: { input_tokens: 1169, total_tokens: 1176, output_tokens: 7 },
    additional_kwargs: {},
    response_metadata: {
      id: 'msg_01Tx9kSNapSg8aUbWZXiS1NL',
      model: 'claude-3-sonnet-20240229',
      usage: [Object],
      stop_reason: 'end_turn',
      stop_sequence: null
    },
    invalid_tool_calls: []
  }
]

```

The search returns the examples whose inputs are most similar to the
query input. We can use this for few-shot prompting a model. The first
step is to create a series of math tools we want to allow the model to
call:

```
import { tool } from "@langchain/core/tools";
import { z } from "zod";

const add = tool(
  (input) => {
    return (input.a + input.b).toString();
  },
  {
    name: "add",
    description: "Add two numbers",
    schema: z.object({
      a: z.number().describe("The first number to add"),
      b: z.number().describe("The second number to add"),
    }),
  }
);

const cos = tool(
  (input) => {
    return Math.cos(input.angle).toString();
  },
  {
    name: "cos",
    description: "Calculate the cosine of an angle (in radians)",
    schema: z.object({
      angle: z.number().describe("The angle in radians"),
    }),
  }
);

const divide = tool(
  (input) => {
    return (input.a / input.b).toString();
  },
  {
    name: "divide",
    description: "Divide two numbers",
    schema: z.object({
      a: z.number().describe("The dividend"),
      b: z.number().describe("The divisor"),
    }),
  }
);

const log = tool(
  (input) => {
    return Math.log(input.value).toString();
  },
  {
    name: "log",
    description: "Calculate the natural logarithm of a number",
    schema: z.object({
      value: z.number().describe("The number to calculate the logarithm of"),
    }),
  }
);

const multiply = tool(
  (input) => {
    return (input.a * input.b).toString();
  },
  {
    name: "multiply",
    description: "Multiply two numbers",
    schema: z.object({
      a: z.number().describe("The first number to multiply"),
      b: z.number().describe("The second number to multiply"),
    }),
  }
);

const negate = tool(
  (input) => {
    return (-input.a).toString();
  },
  {
    name: "negate",
    description: "Negate a number",
    schema: z.object({
      a: z.number().describe("The number to negate"),
    }),
  }
);

const pi = tool(
  () => {
    return Math.PI.toString();
  },
  {
    name: "pi",
    description: "Return the value of pi",
    schema: z.object({}),
  }
);

const power = tool(
  (input) => {
    return Math.pow(input.base, input.exponent).toString();
  },
  {
    name: "power",
    description: "Raise a number to a power",
    schema: z.object({
      base: z.number().describe("The base number"),
      exponent: z.number().describe("The exponent"),
    }),
  }
);

const sin = tool(
  (input) => {
    return Math.sin(input.angle).toString();
  },
  {
    name: "sin",
    description: "Calculate the sine of an angle (in radians)",
    schema: z.object({
      angle: z.number().describe("The angle in radians"),
    }),
  }
);

const subtract = tool(
  (input) => {
    return (input.a - input.b).toString();
  },
  {
    name: "subtract",
    description: "Subtract two numbers",
    schema: z.object({
      a: z.number().describe("The number to subtract from"),
      b: z.number().describe("The number to subtract"),
    }),
  }
);

```

```
import { ChatOpenAI } from "@langchain/openai";
import {
  HumanMessage,
  SystemMessage,
  BaseMessage,
  BaseMessageLike,
} from "@langchain/core/messages";
import { RunnableLambda } from "@langchain/core/runnables";
import { Client as LangSmithClient, Example } from "langsmith";
import { coerceMessageLikeToMessage } from "@langchain/core/messages";

const client = new LangSmithClient();

async function similarExamples(
  input: Record<string, any>
): Promise<Record<string, any>> {
  const examples = await client.similarExamples(input, dataset.id, 5);
  return { ...input, examples };
}

function constructPrompt(input: {
  examples: Example[];
  input: string;
}): BaseMessage[] {
  const instructions = "You are great at using mathematical tools.";
  let messages: BaseMessage[] = [];

  for (const ex of input.examples) {
    // Assuming ex.outputs.output is an array of message-like objects
    messages = messages.concat(
      ex.outputs.output.flatMap((msg: BaseMessageLike) =>
        coerceMessageLikeToMessage(msg)
      )
    );
  }

  const examples = messages.filter((msg) => msg._getType() !== "system");
  examples.forEach((ex) => {
    if (ex._getType() === "human") {
      ex.name = "example_user";
    } else {
      ex.name = "example_assistant";
    }
  });

  return [
    new SystemMessage(instructions),
    ...examples,
    new HumanMessage(input.input),
  ];
}

const llm = new ChatOpenAI({
  model: "gpt-4o",
  temperature: 0,
});
const tools = [
  add,
  cos,
  divide,
  log,
  multiply,
  negate,
  pi,
  power,
  sin,
  subtract,
];
const llmWithTools = llm.bindTools(tools);

const exampleSelector = new RunnableLambda({
  func: similarExamples,
}).withConfig({ runName: "similarExamples" });

const chain = exampleSelector
  .pipe(
    new RunnableLambda({
      func: constructPrompt,
    }).withConfig({
      runName: "constructPrompt",
    })
  )
  .pipe(llmWithTools);

```

```
const aiMsg = await chain.invoke({
  input: "whats the negation of the negation of 3",
  system: false,
});
console.log(aiMsg.tool_calls);

```

```
[
  {
    name: 'negate',
    args: { a: 3 },
    type: 'tool_call',
    id: 'call_SX0dmb4AbFu39KkGQDqPXQwa'
  }
]

```

Looking at the LangSmith trace, we can see that relevant examples were
pulled in in the `similarExamples` step and passed as messages to
ChatOpenAI:
<https://smith.langchain.com/public/20e09618-0746-4973-9382-5b36c3f27083/r>.

---

#### Was this page helpful?

#### You can also leave detailed feedback [on GitHub](https://github.com/langchain-ai/langchainjs/issues/new?assignees=&labels=03+-+Documentation&projects=&template=documentation.yml&title=DOC%3A+%3CPlease+write+a+comprehensive+title+after+the+%27DOC%3A+%27+prefix%3E).

[Previous

How to combine results from multiple retrievers](/docs/how_to/ensemble_retriever)[Next

How to select examples by length](/docs/how_to/example_selectors_length_based)

* [Setup](#setup)

Community

* [Twitter](https://twitter.com/LangChainAI)

GitHub

* [Python](https://github.com/langchain-ai/langchain)
* [JS/TS](https://github.com/langchain-ai/langchainjs)

More

* [Homepage](https://langchain.com)
* [Blog](https://blog.langchain.dev)

Copyright Â© 2025 LangChain, Inc.
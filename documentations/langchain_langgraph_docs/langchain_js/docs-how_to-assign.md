[Skip to main content](#%5F%5Fdocusaurus%5FskipToContent%5Ffallback)

**Help us build the JS tools that power AI apps at companies like Replit, Uber, LinkedIn, GitLab, and more. [Join our team!](https://jobs.ashbyhq.com/langchain/05efa205-8560-43fd-bfcc-3f7697561cfb?utm%5Fsource=https%3A%2F%2Fjs.langchain.com%2F&utm%5Fcampaign=langchainjs%5Fdocs)**

[![ðŸ¦œï¸ðŸ”— Langchain](/img/brand/wordmark.png)![ðŸ¦œï¸ðŸ”— Langchain](/img/brand/wordmark-dark.png)](/)[Integrations](/docs/integrations/platforms/)[API Reference](https://v03.api.js.langchain.com)

[More](#)
* [People](/docs/people/)
* [Community](/docs/community)
* [Error reference](/docs/troubleshooting/errors)
* [External guides](/docs/additional%5Fresources/tutorials)
* [Contributing](/docs/contributing)

[v0.3](#)
* [v0.3](/docs/introduction)
* [v0.2](https://js.langchain.com/v0.2/docs/introduction)
* [v0.1](https://js.langchain.com/v0.1/docs/get%5Fstarted/introduction)

[ðŸ¦œðŸ”—](#)
* [LangSmith](https://smith.langchain.com)
* [LangSmith Docs](https://docs.smith.langchain.com)
* [LangChain Hub](https://smith.langchain.com/hub)
* [LangServe](https://github.com/langchain-ai/langserve)
* [Python Docs](https://python.langchain.com/)

[Chat](https://chatjs.langchain.com)[](https://github.com/langchain-ai/langchainjs)

Search

* [Introduction](/docs/introduction)
* [Tutorials](/docs/tutorials/)  
   * [Build a Question Answering application over a Graph Database](/docs/tutorials/graph)  
   * [Tutorials](/docs/tutorials/)  
   * [Build a simple LLM application with chat models and prompt templates](/docs/tutorials/llm%5Fchain)  
   * [Build a Chatbot](/docs/tutorials/chatbot)  
   * [Build a Retrieval Augmented Generation (RAG) App: Part 2](/docs/tutorials/qa%5Fchat%5Fhistory)  
   * [Build an Extraction Chain](/docs/tutorials/extraction)  
   * [Tagging](/docs/tutorials/classification)  
   * [Build a Retrieval Augmented Generation (RAG) App: Part 1](/docs/tutorials/rag)  
   * [Build a semantic search engine](/docs/tutorials/retrievers)  
   * [Build a Question/Answering system over SQL data](/docs/tutorials/sql%5Fqa)  
   * [Summarize Text](/docs/tutorials/summarization)
* [How-to guides](/docs/how%5Fto/)  
   * [How-to guides](/docs/how%5Fto/)  
   * [How to add memory to chatbots](/docs/how%5Fto/chatbots%5Fmemory)  
   * [How to use example selectors](/docs/how%5Fto/example%5Fselectors)  
   * [Installation](/docs/how%5Fto/installation)  
   * [How to stream responses from an LLM](/docs/how%5Fto/streaming%5Fllm)  
   * [How to stream chat model responses](/docs/how%5Fto/chat%5Fstreaming)  
   * [How to embed text data](/docs/how%5Fto/embed%5Ftext)  
   * [How to use few shot examples in chat models](/docs/how%5Fto/few%5Fshot%5Fexamples%5Fchat)  
   * [How to cache model responses](/docs/how%5Fto/llm%5Fcaching)  
   * [How to cache chat model responses](/docs/how%5Fto/chat%5Fmodel%5Fcaching)  
   * [Richer outputs](/docs/how%5Fto/custom%5Fllm)  
   * [How to use few shot examples](/docs/how%5Fto/few%5Fshot%5Fexamples)  
   * [How to use output parsers to parse an LLM response into structured format](/docs/how%5Fto/output%5Fparser%5Fstructured)  
   * [How to return structured data from a model](/docs/how%5Fto/structured%5Foutput)  
   * [How to add ad-hoc tool calling capability to LLMs and Chat Models](/docs/how%5Fto/tools%5Fprompting)  
   * [Richer outputs](/docs/how%5Fto/custom%5Fchat)  
   * [How to do per-user retrieval](/docs/how%5Fto/qa%5Fper%5Fuser)  
   * [How to track token usage](/docs/how%5Fto/chat%5Ftoken%5Fusage%5Ftracking)  
   * [How to track token usage](/docs/how%5Fto/llm%5Ftoken%5Fusage%5Ftracking)  
   * [How to pass through arguments from one step to the next](/docs/how%5Fto/passthrough)  
   * [How to compose prompts together](/docs/how%5Fto/prompts%5Fcomposition)  
   * [How to use legacy LangChain Agents (AgentExecutor)](/docs/how%5Fto/agent%5Fexecutor)  
   * [How to add values to a chain's state](/docs/how%5Fto/assign)  
   * [How to attach runtime arguments to a Runnable](/docs/how%5Fto/binding)  
   * [How to cache embedding results](/docs/how%5Fto/caching%5Fembeddings)  
   * [How to attach callbacks to a module](/docs/how%5Fto/callbacks%5Fattach)  
   * [How to pass callbacks into a module constructor](/docs/how%5Fto/callbacks%5Fconstructor)  
   * [How to dispatch custom callback events](/docs/how%5Fto/callbacks%5Fcustom%5Fevents)  
   * [How to pass callbacks in at runtime](/docs/how%5Fto/callbacks%5Fruntime)  
   * [How to await callbacks in serverless environments](/docs/how%5Fto/callbacks%5Fserverless)  
   * [How to cancel execution](/docs/how%5Fto/cancel%5Fexecution)  
   * [How to split by character](/docs/how%5Fto/character%5Ftext%5Fsplitter)  
   * [How to init any model in one line](/docs/how%5Fto/chat%5Fmodels%5Funiversal%5Finit)  
   * [How to do retrieval](/docs/how%5Fto/chatbots%5Fretrieval)  
   * [How to add tools to chatbots](/docs/how%5Fto/chatbots%5Ftools)  
   * [How to split code](/docs/how%5Fto/code%5Fsplitter)  
   * [How to do retrieval with contextual compression](/docs/how%5Fto/contextual%5Fcompression)  
   * [How to convert Runnables to Tools](/docs/how%5Fto/convert%5Frunnable%5Fto%5Ftool)  
   * [How to create custom callback handlers](/docs/how%5Fto/custom%5Fcallbacks)  
   * [How to write a custom retriever class](/docs/how%5Fto/custom%5Fretriever)  
   * [How to create Tools](/docs/how%5Fto/custom%5Ftools)  
   * [How to debug your LLM apps](/docs/how%5Fto/debugging)  
   * [How to load CSV data](/docs/how%5Fto/document%5Floader%5Fcsv)  
   * [How to write a custom document loader](/docs/how%5Fto/document%5Floader%5Fcustom)  
   * [How to load data from a directory](/docs/how%5Fto/document%5Floader%5Fdirectory)  
   * [How to load HTML](/docs/how%5Fto/document%5Floader%5Fhtml)  
   * [How to load Markdown](/docs/how%5Fto/document%5Floader%5Fmarkdown)  
   * [How to load PDF files](/docs/how%5Fto/document%5Floader%5Fpdf)  
   * [How to load JSON data](/docs/how%5Fto/document%5Floaders%5Fjson)  
   * [How to combine results from multiple retrievers](/docs/how%5Fto/ensemble%5Fretriever)  
   * [How to select examples from a LangSmith dataset](/docs/how%5Fto/example%5Fselectors%5Flangsmith)  
   * [How to select examples by length](/docs/how%5Fto/example%5Fselectors%5Flength%5Fbased)  
   * [How to select examples by similarity](/docs/how%5Fto/example%5Fselectors%5Fsimilarity)  
   * [How to use reference examples](/docs/how%5Fto/extraction%5Fexamples)  
   * [How to handle long text](/docs/how%5Fto/extraction%5Flong%5Ftext)  
   * [How to do extraction without using function calling](/docs/how%5Fto/extraction%5Fparse)  
   * [Fallbacks](/docs/how%5Fto/fallbacks)  
   * [Few Shot Prompt Templates](/docs/how%5Fto/few%5Fshot)  
   * [How to filter messages](/docs/how%5Fto/filter%5Fmessages)  
   * [How to run custom functions](/docs/how%5Fto/functions)  
   * [How to build an LLM generated UI](/docs/how%5Fto/generative%5Fui)  
   * [How to construct knowledge graphs](/docs/how%5Fto/graph%5Fconstructing)  
   * [How to map values to a database](/docs/how%5Fto/graph%5Fmapping)  
   * [How to improve results with prompting](/docs/how%5Fto/graph%5Fprompting)  
   * [How to add a semantic layer over the database](/docs/how%5Fto/graph%5Fsemantic)  
   * [How to reindex data to keep your vectorstore in-sync with the underlying data source](/docs/how%5Fto/indexing)  
   * [LangChain Expression Language Cheatsheet](/docs/how%5Fto/lcel%5Fcheatsheet)  
   * [How to get log probabilities](/docs/how%5Fto/logprobs)  
   * [How to merge consecutive messages of the same type](/docs/how%5Fto/merge%5Fmessage%5Fruns)  
   * [How to add message history](/docs/how%5Fto/message%5Fhistory)  
   * [How to migrate from legacy LangChain agents to LangGraph](/docs/how%5Fto/migrate%5Fagent)  
   * [How to generate multiple embeddings per document](/docs/how%5Fto/multi%5Fvector)  
   * [How to pass multimodal data directly to models](/docs/how%5Fto/multimodal%5Finputs)  
   * [How to use multimodal prompts](/docs/how%5Fto/multimodal%5Fprompts)  
   * [How to generate multiple queries to retrieve data for](/docs/how%5Fto/multiple%5Fqueries)  
   * [How to try to fix errors in output parsing](/docs/how%5Fto/output%5Fparser%5Ffixing)  
   * [How to parse JSON output](/docs/how%5Fto/output%5Fparser%5Fjson)  
   * [How to parse XML output](/docs/how%5Fto/output%5Fparser%5Fxml)  
   * [How to invoke runnables in parallel](/docs/how%5Fto/parallel)  
   * [How to retrieve the whole document for a chunk](/docs/how%5Fto/parent%5Fdocument%5Fretriever)  
   * [How to partially format prompt templates](/docs/how%5Fto/prompts%5Fpartial)  
   * [How to add chat history](/docs/how%5Fto/qa%5Fchat%5Fhistory%5Fhow%5Fto)  
   * [How to return citations](/docs/how%5Fto/qa%5Fcitations)  
   * [How to return sources](/docs/how%5Fto/qa%5Fsources)  
   * [How to stream from a question-answering chain](/docs/how%5Fto/qa%5Fstreaming)  
   * [How to construct filters](/docs/how%5Fto/query%5Fconstructing%5Ffilters)  
   * [How to add examples to the prompt](/docs/how%5Fto/query%5Ffew%5Fshot)  
   * [How to deal with high cardinality categorical variables](/docs/how%5Fto/query%5Fhigh%5Fcardinality)  
   * [How to handle multiple queries](/docs/how%5Fto/query%5Fmultiple%5Fqueries)  
   * [How to handle multiple retrievers](/docs/how%5Fto/query%5Fmultiple%5Fretrievers)  
   * [How to handle cases where no queries are generated](/docs/how%5Fto/query%5Fno%5Fqueries)  
   * [How to recursively split text by characters](/docs/how%5Fto/recursive%5Ftext%5Fsplitter)  
   * [How to reduce retrieval latency](/docs/how%5Fto/reduce%5Fretrieval%5Flatency)  
   * [How to route execution within a chain](/docs/how%5Fto/routing)  
   * [How to do "self-querying" retrieval](/docs/how%5Fto/self%5Fquery)  
   * [How to chain runnables](/docs/how%5Fto/sequence)  
   * [How to split text by tokens](/docs/how%5Fto/split%5Fby%5Ftoken)  
   * [How to deal with large databases](/docs/how%5Fto/sql%5Flarge%5Fdb)  
   * [How to use prompting to improve results](/docs/how%5Fto/sql%5Fprompting)  
   * [How to do query validation](/docs/how%5Fto/sql%5Fquery%5Fchecking)  
   * [How to stream agent data to the client](/docs/how%5Fto/stream%5Fagent%5Fclient)  
   * [How to stream structured output to the client](/docs/how%5Fto/stream%5Ftool%5Fclient)  
   * [How to stream](/docs/how%5Fto/streaming)  
   * [How to create a time-weighted retriever](/docs/how%5Fto/time%5Fweighted%5Fvectorstore)  
   * [How to return artifacts from a tool](/docs/how%5Fto/tool%5Fartifacts)  
   * [How to use chat models to call tools](/docs/how%5Fto/tool%5Fcalling)  
   * [How to disable parallel tool calling](/docs/how%5Fto/tool%5Fcalling%5Fparallel)  
   * [How to call tools with multimodal data](/docs/how%5Fto/tool%5Fcalls%5Fmultimodal)  
   * [How to force tool calling behavior](/docs/how%5Fto/tool%5Fchoice)  
   * [How to access the RunnableConfig from a tool](/docs/how%5Fto/tool%5Fconfigure)  
   * [How to pass tool outputs to chat models](/docs/how%5Fto/tool%5Fresults%5Fpass%5Fto%5Fmodel)  
   * [How to pass run time values to tools](/docs/how%5Fto/tool%5Fruntime)  
   * [How to stream events from a tool](/docs/how%5Fto/tool%5Fstream%5Fevents)  
   * [How to stream tool calls](/docs/how%5Fto/tool%5Fstreaming)  
   * [How to use LangChain tools](/docs/how%5Fto/tools%5Fbuiltin)  
   * [How to handle tool errors](/docs/how%5Fto/tools%5Ferror)  
   * [How to use few-shot prompting with tool calling](/docs/how%5Fto/tools%5Ffew%5Fshot)  
   * [How to trim messages](/docs/how%5Fto/trim%5Fmessages)  
   * [How use a vector store to retrieve data](/docs/how%5Fto/vectorstore%5Fretriever)  
   * [How to create and query vector stores](/docs/how%5Fto/vectorstores)
* [Conceptual Guide](/docs/concepts/)  
   * [Agents](/docs/concepts/agents)  
   * [Architecture](/docs/concepts/architecture)  
   * [Callbacks](/docs/concepts/callbacks)  
   * [Chat history](/docs/concepts/chat%5Fhistory)  
   * [Chat models](/docs/concepts/chat%5Fmodels)  
   * [Document loaders](/docs/concepts/document%5Floaders)  
   * [Embedding models](/docs/concepts/embedding%5Fmodels)  
   * [Evaluation](/docs/concepts/evaluation)  
   * [Example selectors](/docs/concepts/example%5Fselectors)  
   * [Few-shot prompting](/docs/concepts/few%5Fshot%5Fprompting)  
   * [Conceptual guide](/docs/concepts/)  
   * [Key-value stores](/docs/concepts/key%5Fvalue%5Fstores)  
   * [LangChain Expression Language (LCEL)](/docs/concepts/lcel)  
   * [Messages](/docs/concepts/messages)  
   * [Multimodality](/docs/concepts/multimodality)  
   * [Output parsers](/docs/concepts/output%5Fparsers)  
   * [Prompt Templates](/docs/concepts/prompt%5Ftemplates)  
   * [Retrieval augmented generation (rag)](/docs/concepts/rag)  
   * [Retrieval](/docs/concepts/retrieval)  
   * [Retrievers](/docs/concepts/retrievers)  
   * [Runnable interface](/docs/concepts/runnables)  
   * [Streaming](/docs/concepts/streaming)  
   * [Structured outputs](/docs/concepts/structured%5Foutputs)  
   * [t](/docs/concepts/t)  
   * [String-in, string-out llms](/docs/concepts/text%5Fllms)  
   * [Text splitters](/docs/concepts/text%5Fsplitters)  
   * [Tokens](/docs/concepts/tokens)  
   * [Tool calling](/docs/concepts/tool%5Fcalling)  
   * [Tools](/docs/concepts/tools)  
   * [Tracing](/docs/concepts/tracing)  
   * [Vector stores](/docs/concepts/vectorstores)  
   * [Why LangChain?](/docs/concepts/why%5Flangchain)
* Ecosystem  
   * [ðŸ¦œðŸ› ï¸ LangSmith](https://docs.smith.langchain.com/)  
   * [ðŸ¦œðŸ•¸ï¸ LangGraph.js](https://langchain-ai.github.io/langgraphjs/)
* Versions  
   * [v0.3](/docs/versions/v0%5F3/)  
   * [v0.2](/docs/versions/v0%5F2/)  
   * [Migrating from v0.0 memory](/docs/versions/migrating%5Fmemory/)  
         * [How to migrate to LangGraph memory](/docs/versions/migrating%5Fmemory/)  
         * [How to use BaseChatMessageHistory with LangGraph](/docs/versions/migrating%5Fmemory/chat%5Fhistory)  
         * [Migrating off ConversationTokenBufferMemory](/docs/versions/migrating%5Fmemory/conversation%5Fbuffer%5Fwindow%5Fmemory)  
         * [Migrating off ConversationSummaryMemory or ConversationSummaryBufferMemory](/docs/versions/migrating%5Fmemory/conversation%5Fsummary%5Fmemory)  
   * [Release Policy](/docs/versions/release%5Fpolicy)
* [Security](/docs/security)

* [How-to guides](/docs/how%5Fto/)
* How to add values to a chain's state

On this page

# How to add values to a chain's state

Prerequisites

This guide assumes familiarity with the following concepts:

* [LangChain Expression Language (LCEL)](/docs/concepts/lcel)
* [Chaining runnables](/docs/how%5Fto/sequence/)
* [Calling runnables in parallel](/docs/how%5Fto/parallel/)
* [Custom functions](/docs/how%5Fto/functions/)
* [Passing data through](/docs/how%5Fto/passthrough)

An alternate way of [passing data through](/docs/how%5Fto/passthrough)steps of a chain is to leave the current values of the chain state unchanged while assigning a new value under a given key. The[RunnablePassthrough.assign()](https://api.js.langchain.com/classes/langchain%5Fcore.runnables.RunnablePassthrough.html#assign-2)static method takes an input value and adds the extra arguments passed to the assign function.

This is useful in the common [LangChain Expression Language](/docs/concepts/lcel) pattern of additively creating a dictionary to use as input to a later step.

Hereâ€™s an example:

```
import {
  RunnableParallel,
  RunnablePassthrough,
} from "@langchain/core/runnables";

const runnable = RunnableParallel.from({
  extra: RunnablePassthrough.assign({
    mult: (input: { num: number }) => input.num * 3,
    modified: (input: { num: number }) => input.num + 1,
  }),
});

await runnable.invoke({ num: 1 });

```

```
{ extra: { num: 1, mult: 3, modified: 2 } }

```

Letâ€™s break down whatâ€™s happening here.

* The input to the chain is `{"num": 1}`. This is passed into a`RunnableParallel`, which invokes the runnables it is passed in parallel with that input.
* The value under the `extra` key is invoked.`RunnablePassthrough.assign()` keeps the original keys in the input dict (`{"num": 1}`), and assigns a new key called `mult`. The value is `lambda x: x["num"] * 3)`, which is `3`. Thus, the result is`{"num": 1, "mult": 3}`.
* `{"num": 1, "mult": 3}` is returned to the `RunnableParallel` call, and is set as the value to the key `extra`.
* At the same time, the `modified` key is called. The result is `2`, since the lambda extracts a key called `"num"` from its input and adds one.

Thus, the result is `{'extra': {'num': 1, 'mult': 3}, 'modified': 2}`.

## Streaming[â€‹](#streaming "Direct link to Streaming")

One convenient feature of this method is that it allows values to pass through as soon as they are available. To show this off, weâ€™ll use`RunnablePassthrough.assign()` to immediately return source docs in a retrieval chain:

tip

See [this section for general instructions on installing integration packages](/docs/how%5Fto/installation#installing-integration-packages).

* npm
* yarn
* pnpm

```
npm i @langchain/openai @langchain/core

```

```
yarn add @langchain/openai @langchain/core

```

```
pnpm add @langchain/openai @langchain/core

```

```
import { StringOutputParser } from "@langchain/core/output_parsers";
import { ChatPromptTemplate } from "@langchain/core/prompts";
import {
  RunnablePassthrough,
  RunnableSequence,
} from "@langchain/core/runnables";
import { ChatOpenAI, OpenAIEmbeddings } from "@langchain/openai";
import { MemoryVectorStore } from "langchain/vectorstores/memory";

const vectorstore = await MemoryVectorStore.fromDocuments(
  [{ pageContent: "harrison worked at kensho", metadata: {} }],
  new OpenAIEmbeddings()
);

const retriever = vectorstore.asRetriever();

const template = `Answer the question based only on the following context:
{context}

Question: {question}
`;

const prompt = ChatPromptTemplate.fromTemplate(template);

const model = new ChatOpenAI({ model: "gpt-4o" });

const generationChain = prompt.pipe(model).pipe(new StringOutputParser());

const retrievalChain = RunnableSequence.from([
  {
    context: retriever.pipe((docs) => docs[0].pageContent),
    question: new RunnablePassthrough(),
  },
  RunnablePassthrough.assign({ output: generationChain }),
]);

const stream = await retrievalChain.stream("where did harrison work?");

for await (const chunk of stream) {
  console.log(chunk);
}

```

```
{ question: "where did harrison work?" }
{ context: "harrison worked at kensho" }
{ output: "" }
{ output: "H" }
{ output: "arrison" }
{ output: " worked" }
{ output: " at" }
{ output: " Kens" }
{ output: "ho" }
{ output: "." }
{ output: "" }

```

We can see that the first chunk contains the original `"question"` since that is immediately available. The second chunk contains `"context"`since the retriever finishes second. Finally, the output from the`generation_chain` streams in chunks as soon as it is available.

## Next steps[â€‹](#next-steps "Direct link to Next steps")

Now youâ€™ve learned how to pass data through your chains to help to help format the data flowing through your chains.

To learn more, see the other how-to guides on runnables in this section.

---

#### Was this page helpful?

  
#### You can also leave detailed feedback [on GitHub](https://github.com/langchain-ai/langchainjs/issues/new?assignees=&labels=03+-+Documentation&projects=&template=documentation.yml&title=DOC%3A+%3CPlease+write+a+comprehensive+title+after+the+%27DOC%3A+%27+prefix%3E).

[PreviousHow to use legacy LangChain Agents (AgentExecutor)](/docs/how%5Fto/agent%5Fexecutor)[NextHow to attach runtime arguments to a Runnable](/docs/how%5Fto/binding)

* [Streaming](#streaming)
* [Next steps](#next-steps)

Community

* [Twitter](https://twitter.com/LangChainAI)

GitHub

* [Python](https://github.com/langchain-ai/langchain)
* [JS/TS](https://github.com/langchain-ai/langchainjs)

More

* [Homepage](https://langchain.com)
* [Blog](https://blog.langchain.dev)

Copyright Â© 2025 LangChain, Inc.
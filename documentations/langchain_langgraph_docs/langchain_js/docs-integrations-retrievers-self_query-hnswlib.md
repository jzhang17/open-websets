[Skip to main content](#__docusaurus_skipToContent_fallback)

**Help us build the JS tools that power AI apps at companies like Replit, Uber, LinkedIn, GitLab, and more. [Join our team!](https://jobs.ashbyhq.com/langchain/05efa205-8560-43fd-bfcc-3f7697561cfb?utm_source=https%3A%2F%2Fjs.langchain.com%2F&utm_campaign=langchainjs_docs)**

[![ü¶úÔ∏èüîó Langchain](/img/brand/wordmark.png)![ü¶úÔ∏èüîó Langchain](/img/brand/wordmark-dark.png)](/)[Integrations](/docs/integrations/platforms/)[API Reference](https://v03.api.js.langchain.com)

More

* [People](/docs/people/)
* [Community](/docs/community)
* [Error reference](/docs/troubleshooting/errors)
* [External guides](/docs/additional_resources/tutorials)
* [Contributing](/docs/contributing)

v0.3

* [v0.3](/docs/introduction)
* [v0.2](https://js.langchain.com/v0.2/docs/introduction)
* [v0.1](https://js.langchain.com/v0.1/docs/get_started/introduction)

ü¶úüîó

* [LangSmith](https://smith.langchain.com)
* [LangSmith Docs](https://docs.smith.langchain.com)
* [LangChain Hub](https://smith.langchain.com/hub)
* [LangServe](https://github.com/langchain-ai/langserve)
* [Python Docs](https://python.langchain.com/)

[Chat](https://chatjs.langchain.com)

Search

* [Providers](/docs/integrations/platforms/)

  + [Providers](/docs/integrations/platforms/)
  + [Anthropic](/docs/integrations/platforms/anthropic)
  + [AWS](/docs/integrations/platforms/aws)
  + [Google](/docs/integrations/platforms/google)
  + [Microsoft](/docs/integrations/platforms/microsoft)
  + [OpenAI](/docs/integrations/platforms/openai)
* [Components](/docs/integrations/components)

  + [Chat models](/docs/integrations/chat/)

    - [Chat models](/docs/integrations/chat/)
    - [Alibaba Tongyi](/docs/integrations/chat/alibaba_tongyi)
    - [Anthropic](/docs/integrations/chat/anthropic)
    - [Arcjet Redact](/docs/integrations/chat/arcjet)
    - [Azure OpenAI](/docs/integrations/chat/azure)
    - [Baidu Qianfan](/docs/integrations/chat/baidu_qianfan)
    - [Baidu Wenxin](/docs/integrations/chat/baidu_wenxin)
    - [Amazon Bedrock](/docs/integrations/chat/bedrock)
    - [Amazon Bedrock Converse](/docs/integrations/chat/bedrock_converse)
    - [Cerebras](/docs/integrations/chat/cerebras)
    - [Cloudflare Workers AI](/docs/integrations/chat/cloudflare_workersai)
    - [Cohere](/docs/integrations/chat/cohere)
    - [Deep Infra](/docs/integrations/chat/deep_infra)
    - [DeepSeek](/docs/integrations/chat/deepseek)
    - [DeepSeek](/docs/integrations/chat/deepseek)
    - [Fake LLM](/docs/integrations/chat/fake)
    - [Fireworks](/docs/integrations/chat/fireworks)
    - [Friendli](/docs/integrations/chat/friendli)
    - [Google GenAI](/docs/integrations/chat/google_generativeai)
    - [Google Vertex AI](/docs/integrations/chat/google_vertex_ai)
    - [Groq](/docs/integrations/chat/groq)
    - [IBM watsonx.ai](/docs/integrations/chat/ibm)
    - [Llama CPP](/docs/integrations/chat/llama_cpp)
    - [Minimax](/docs/integrations/chat/minimax)
    - [MistralAI](/docs/integrations/chat/mistral)
    - [Moonshot](/docs/integrations/chat/moonshot)
    - [NIBittensorChatModel](/docs/integrations/chat/ni_bittensor)
    - [Novita AI](/docs/integrations/chat/novita)
    - [Ollama](/docs/integrations/chat/ollama)
    - [Ollama Functions](/docs/integrations/chat/ollama_functions)
    - [OpenAI](/docs/integrations/chat/openai)
    - [Perplexity](/docs/integrations/chat/perplexity)
    - [Perplexity](/docs/integrations/chat/perplexity)
    - [PremAI](/docs/integrations/chat/premai)
    - [PromptLayer OpenAI](/docs/integrations/chat/prompt_layer_openai)
    - [Tencent Hunyuan](/docs/integrations/chat/tencent_hunyuan)
    - [Together](/docs/integrations/chat/togetherai)
    - [WebLLM](/docs/integrations/chat/web_llm)
    - [xAI](/docs/integrations/chat/xai)
    - [YandexGPT](/docs/integrations/chat/yandex)
    - [ZhipuAI](/docs/integrations/chat/zhipuai)
  + [LLMs](/docs/integrations/llms/)

    - [LLMs](/docs/integrations/llms/)
    - [AI21](/docs/integrations/llms/ai21)
    - [AlephAlpha](/docs/integrations/llms/aleph_alpha)
    - [Arcjet Redact](/docs/integrations/llms/arcjet)
    - [AWS SageMakerEndpoint](/docs/integrations/llms/aws_sagemaker)
    - [Azure OpenAI](/docs/integrations/llms/azure)
    - [Bedrock](/docs/integrations/llms/bedrock)
    - [ChromeAI](/docs/integrations/llms/chrome_ai)
    - [Cloudflare Workers AI](/docs/integrations/llms/cloudflare_workersai)
    - [Cohere](/docs/integrations/llms/cohere)
    - [Deep Infra](/docs/integrations/llms/deep_infra)
    - [Fireworks](/docs/integrations/llms/fireworks)
    - [Friendli](/docs/integrations/llms/friendli)
    - [Google Vertex AI](/docs/integrations/llms/google_vertex_ai)
    - [Gradient AI](/docs/integrations/llms/gradient_ai)
    - [HuggingFaceInference](/docs/integrations/llms/huggingface_inference)
    - [IBM watsonx.ai](/docs/integrations/llms/ibm)
    - [JigsawStack Prompt Engine](/docs/integrations/llms/jigsawstack)
    - [Layerup Security](/docs/integrations/llms/layerup_security)
    - [Llama CPP](/docs/integrations/llms/llama_cpp)
    - [MistralAI](/docs/integrations/llms/mistral)
    - [NIBittensor](/docs/integrations/llms/ni_bittensor)
    - [Ollama](/docs/integrations/llms/ollama)
    - [OpenAI](/docs/integrations/llms/openai)
    - [PromptLayer OpenAI](/docs/integrations/llms/prompt_layer_openai)
    - [RaycastAI](/docs/integrations/llms/raycast)
    - [Replicate](/docs/integrations/llms/replicate)
    - [Together AI](/docs/integrations/llms/together)
    - [Writer](/docs/integrations/llms/writer)
    - [YandexGPT](/docs/integrations/llms/yandex)
  + [Embedding models](/docs/integrations/text_embedding/)

    - [Embeddings](/docs/integrations/text_embedding/)
    - [Alibaba Tongyi](/docs/integrations/text_embedding/alibaba_tongyi)
    - [Azure OpenAI](/docs/integrations/text_embedding/azure_openai)
    - [Baidu Qianfan](/docs/integrations/text_embedding/baidu_qianfan)
    - [Amazon Bedrock](/docs/integrations/text_embedding/bedrock)
    - [ByteDance Doubao](/docs/integrations/text_embedding/bytedance_doubao)
    - [Cloudflare Workers AI](/docs/integrations/text_embedding/cloudflare_ai)
    - [Cohere](/docs/integrations/text_embedding/cohere)
    - [DeepInfra](/docs/integrations/text_embedding/deepinfra)
    - [Fireworks](/docs/integrations/text_embedding/fireworks)
    - [Google Generative AI](/docs/integrations/text_embedding/google_generativeai)
    - [Google Vertex AI](/docs/integrations/text_embedding/google_vertex_ai)
    - [Gradient AI](/docs/integrations/text_embedding/gradient_ai)
    - [HuggingFace Inference](/docs/integrations/text_embedding/hugging_face_inference)
    - [IBM watsonx.ai](/docs/integrations/text_embedding/ibm)
    - [Jina](/docs/integrations/text_embedding/jina)
    - [Llama CPP](/docs/integrations/text_embedding/llama_cpp)
    - [Minimax](/docs/integrations/text_embedding/minimax)
    - [MistralAI](/docs/integrations/text_embedding/mistralai)
    - [Mixedbread AI](/docs/integrations/text_embedding/mixedbread_ai)
    - [Nomic](/docs/integrations/text_embedding/nomic)
    - [Ollama](/docs/integrations/text_embedding/ollama)
    - [OpenAI](/docs/integrations/text_embedding/openai)
    - [Pinecone](/docs/integrations/text_embedding/pinecone)
    - [Prem AI](/docs/integrations/text_embedding/premai)
    - [Tencent Hunyuan](/docs/integrations/text_embedding/tencent_hunyuan)
    - [TensorFlow](/docs/integrations/text_embedding/tensorflow)
    - [TogetherAI](/docs/integrations/text_embedding/togetherai)
    - [HuggingFace Transformers](/docs/integrations/text_embedding/transformers)
    - [Voyage AI](/docs/integrations/text_embedding/voyageai)
    - [ZhipuAI](/docs/integrations/text_embedding/zhipuai)
  + [Document loaders](/docs/integrations/document_loaders/)
  + [Vector stores](/docs/integrations/vectorstores/)

    - [Vector stores](/docs/integrations/vectorstores/)
    - [AnalyticDB](/docs/integrations/vectorstores/analyticdb)
    - [Astra DB](/docs/integrations/vectorstores/astradb)
    - [Azion EdgeSQL](/docs/integrations/vectorstores/azion-edgesql)
    - [Azion EdgeSQL](/docs/integrations/vectorstores/azion-edgesql)
    - [Azure AI Search](/docs/integrations/vectorstores/azure_aisearch)
    - [Azure Cosmos DB for MongoDB vCore](/docs/integrations/vectorstores/azure_cosmosdb_mongodb)
    - [Azure Cosmos DB for NoSQL](/docs/integrations/vectorstores/azure_cosmosdb_nosql)
    - [Cassandra](/docs/integrations/vectorstores/cassandra)
    - [Chroma](/docs/integrations/vectorstores/chroma)
    - [ClickHouse](/docs/integrations/vectorstores/clickhouse)
    - [CloseVector](/docs/integrations/vectorstores/closevector)
    - [Cloudflare Vectorize](/docs/integrations/vectorstores/cloudflare_vectorize)
    - [Convex](/docs/integrations/vectorstores/convex)
    - [Couchbase](/docs/integrations/vectorstores/couchbase)
    - [Elasticsearch](/docs/integrations/vectorstores/elasticsearch)
    - [Faiss](/docs/integrations/vectorstores/faiss)
    - [Google Cloud SQL for PostgreSQL](/docs/integrations/vectorstores/google_cloudsql_pg)
    - [Google Cloud SQL for PostgreSQL](/docs/integrations/vectorstores/google_cloudsql_pg)
    - [Google Vertex AI Matching Engine](/docs/integrations/vectorstores/googlevertexai)
    - [SAP HANA Cloud Vector Engine](/docs/integrations/vectorstores/hanavector)
    - [HNSWLib](/docs/integrations/vectorstores/hnswlib)
    - [LanceDB](/docs/integrations/vectorstores/lancedb)
    - [libSQL](/docs/integrations/vectorstores/libsql)
    - [MariaDB](/docs/integrations/vectorstores/mariadb)
    - [In-memory](/docs/integrations/vectorstores/memory)
    - [Milvus](/docs/integrations/vectorstores/milvus)
    - [Momento Vector Index (MVI)](/docs/integrations/vectorstores/momento_vector_index)
    - [MongoDB Atlas](/docs/integrations/vectorstores/mongodb_atlas)
    - [MyScale](/docs/integrations/vectorstores/myscale)
    - [Neo4j Vector Index](/docs/integrations/vectorstores/neo4jvector)
    - [Neon Postgres](/docs/integrations/vectorstores/neon)
    - [OpenSearch](/docs/integrations/vectorstores/opensearch)
    - [PGVector](/docs/integrations/vectorstores/pgvector)
    - [Pinecone](/docs/integrations/vectorstores/pinecone)
    - [Prisma](/docs/integrations/vectorstores/prisma)
    - [Qdrant](/docs/integrations/vectorstores/qdrant)
    - [Redis](/docs/integrations/vectorstores/redis)
    - [Rockset](/docs/integrations/vectorstores/rockset)
    - [SingleStore](/docs/integrations/vectorstores/singlestore)
    - [Supabase](/docs/integrations/vectorstores/supabase)
    - [Tigris](/docs/integrations/vectorstores/tigris)
    - [Turbopuffer](/docs/integrations/vectorstores/turbopuffer)
    - [TypeORM](/docs/integrations/vectorstores/typeorm)
    - [Typesense](/docs/integrations/vectorstores/typesense)
    - [Upstash Vector](/docs/integrations/vectorstores/upstash)
    - [USearch](/docs/integrations/vectorstores/usearch)
    - [Vectara](/docs/integrations/vectorstores/vectara)
    - [Vercel Postgres](/docs/integrations/vectorstores/vercel_postgres)
    - [Voy](/docs/integrations/vectorstores/voy)
    - [Weaviate](/docs/integrations/vectorstores/weaviate)
    - [Xata](/docs/integrations/vectorstores/xata)
    - [Zep Open Source](/docs/integrations/vectorstores/zep)
    - [Zep Cloud](/docs/integrations/vectorstores/zep_cloud)
  + [Retrievers](/docs/integrations/retrievers/)

    - [Retrievers](/docs/integrations/retrievers/)
    - [ArxivRetriever](/docs/integrations/retrievers/arxiv-retriever)
    - [Azion EdgeSQL](/docs/integrations/retrievers/azion-edgesql)
    - [Azion EdgeSQL](/docs/integrations/retrievers/azion-edgesql)
    - [Knowledge Bases for Amazon Bedrock](/docs/integrations/retrievers/bedrock-knowledge-bases)
    - [BM25](/docs/integrations/retrievers/bm25)
    - [Chaindesk Retriever](/docs/integrations/retrievers/chaindesk-retriever)
    - [ChatGPT Plugin Retriever](/docs/integrations/retrievers/chatgpt-retriever-plugin)
    - [Dria Retriever](/docs/integrations/retrievers/dria)
    - [Exa](/docs/integrations/retrievers/exa)
    - [HyDE Retriever](/docs/integrations/retrievers/hyde)
    - [Amazon Kendra Retriever](/docs/integrations/retrievers/kendra-retriever)
    - [Metal Retriever](/docs/integrations/retrievers/metal-retriever)
    - [Self-querying retrievers](/docs/integrations/retrievers/self_query/)

      * [Chroma](/docs/integrations/retrievers/self_query/chroma)
      * [HNSWLib](/docs/integrations/retrievers/self_query/hnswlib)
      * [In-memory](/docs/integrations/retrievers/self_query/memory)
      * [Pinecone](/docs/integrations/retrievers/self_query/pinecone)
      * [Qdrant](/docs/integrations/retrievers/self_query/qdrant)
      * [Supabase](/docs/integrations/retrievers/self_query/supabase)
      * [Vectara](/docs/integrations/retrievers/self_query/vectara)
      * [Weaviate](/docs/integrations/retrievers/self_query/weaviate)
    - [Supabase Hybrid Search](/docs/integrations/retrievers/supabase-hybrid)
    - [Tavily Search API](/docs/integrations/retrievers/tavily)
    - [Time-Weighted Retriever](/docs/integrations/retrievers/time-weighted-retriever)
    - [Vespa Retriever](/docs/integrations/retrievers/vespa-retriever)
    - [Zep Cloud Retriever](/docs/integrations/retrievers/zep-cloud-retriever)
    - [Zep Open Source Retriever](/docs/integrations/retrievers/zep-retriever)
  + [Tools/Toolkits](/docs/integrations/tools/)

    - [Tools and Toolkits](/docs/integrations/tools/)
    - [ChatGPT Plugins](/docs/integrations/tools/aiplugin-tool)
    - [Azure Container Apps Dynamic Sessions](/docs/integrations/tools/azure_dynamic_sessions)
    - [Connery Action Tool](/docs/integrations/tools/connery)
    - [Dall-E Tool](/docs/integrations/tools/dalle)
    - [Discord Tool](/docs/integrations/tools/discord)
    - [DuckDuckGoSearch](/docs/integrations/tools/duckduckgo_search)
    - [ExaSearchResults](/docs/integrations/tools/exa_search)
    - [Gmail Tool](/docs/integrations/tools/gmail)
    - [GOAT](/docs/integrations/tools/goat)
    - [Google Calendar Tool](/docs/integrations/tools/google_calendar)
    - [Google Places Tool](/docs/integrations/tools/google_places)
    - [Google Routes Tool](/docs/integrations/tools/google_routes)
    - [Google Scholar](/docs/integrations/tools/google_scholar)
    - [Google Trends Tool](/docs/integrations/tools/google_trends)
    - [JigsawStack Tool](/docs/integrations/tools/jigsawstack)
    - [Agent with AWS Lambda](/docs/integrations/tools/lambda_agent)
    - [Python interpreter tool](/docs/integrations/tools/pyinterpreter)
    - [SearchApi tool](/docs/integrations/tools/searchapi)
    - [Searxng Search tool](/docs/integrations/tools/searxng)
    - [SerpAPI](/docs/integrations/tools/serpapi)
    - [StackExchange Tool](/docs/integrations/tools/stackexchange)
    - [Stagehand AI Web Automation Toolkit](/docs/integrations/tools/stagehand)
    - [Tavily Extract](/docs/integrations/tools/tavily_extract)
    - [Tavily Search](/docs/integrations/tools/tavily_search)
    - [Tavily Search (Community, Deprecated)](/docs/integrations/tools/tavily_search_community)
    - [Web Browser Tool](/docs/integrations/tools/webbrowser)
    - [Wikipedia tool](/docs/integrations/tools/wikipedia)
    - [WolframAlpha Tool](/docs/integrations/tools/wolframalpha)
    - [Agent with Zapier NLA Integration](/docs/integrations/tools/zapier_agent)
  + [Toolkits](/docs/integrations/tools/)

    - [Toolkits](/docs/integrations/toolkits/)
    - [Connery Toolkit](/docs/integrations/toolkits/connery)
    - [WatsonxToolkit](/docs/integrations/toolkits/ibm)
    - [WatsonxToolkit](/docs/integrations/toolkits/ibm)
    - [JSON Agent Toolkit](/docs/integrations/toolkits/json)
    - [OpenApi Toolkit](/docs/integrations/toolkits/openapi)
    - [AWS Step Functions Toolkit](/docs/integrations/toolkits/sfn_agent)
    - [Sql Toolkit](/docs/integrations/toolkits/sql)
    - [VectorStore Toolkit](/docs/integrations/toolkits/vectorstore)
  + [Key-value stores](/docs/integrations/stores/)

    - [Cassandra KV](/docs/integrations/stores/cassandra_storage)
    - [File System Store](/docs/integrations/stores/file_system)
    - [InMemory Store](/docs/integrations/stores/in_memory)
    - [Key-value stores](/docs/integrations/stores/)
    - [IORedis](/docs/integrations/stores/ioredis_storage)
    - [Upstash Redis](/docs/integrations/stores/upstash_redis_storage)
    - [Vercel KV](/docs/integrations/stores/vercel_kv_storage)
  + [Other](/docs/integrations/document_transformers)

* [Components](/docs/integrations/components)
* [Retrievers](/docs/integrations/retrievers/)
* [Self-querying retrievers](/docs/integrations/retrievers/self_query/)
* HNSWLib

On this page

# HNSWLib

This guide will help you getting started with such a retriever backed by
a [HNSWLib vector store](/docs/integrations/vectorstores/hnswlib). For
detailed documentation of all features and configurations head to the
[API
reference](https://api.js.langchain.com/classes/langchain.retrievers_self_query.SelfQueryRetriever.html).

## Overview[‚Äã](#overview "Direct link to Overview")

A [self-query retriever](/docs/how_to/self_query/) retrieves documents
by dynamically generating metadata filters based on some input query.
This allows the retriever to account for underlying document metadata in
addition to pure semantic similarity when fetching results.

It uses a module called a `Translator` that generates a filter based on
information about metadata fields and the query language that a given
vector store supports.

### Integration details[‚Äã](#integration-details "Direct link to Integration details")

| Backing vector store | Self-host | Cloud offering | Package | Py support |
| --- | --- | --- | --- | --- |
| [`HNSWLib`](https://api.js.langchain.com/classes/langchain_community_vectorstores_hnswlib.HNSWLib.html) | ‚úÖ | ‚ùå | [`@langchain/community`](https://www.npmjs.com/package/%40langchain/community) | ‚ùå |

## Setup[‚Äã](#setup "Direct link to Setup")

Set up a HNSWLib instance as documented
[here](/docs/integrations/vectorstores/hnswlib).

If you want to get automated tracing from individual queries, you can
also set your [LangSmith](https://docs.smith.langchain.com/) API key by
uncommenting below:

```
// process.env.LANGSMITH_API_KEY = "<YOUR API KEY HERE>";
// process.env.LANGSMITH_TRACING = "true";

```

### Installation[‚Äã](#installation "Direct link to Installation")

The vector store lives in the `@langchain/community` package. You‚Äôll
also need to install the `langchain` package to import the main
`SelfQueryRetriever` class.

For this example, we‚Äôll also use OpenAI embeddings, so you‚Äôll need to
install the `@langchain/openai` package and [obtain an API
key](https://platform.openai.com):

tip

See [this section for general instructions on installing integration packages](/docs/how_to/installation#installing-integration-packages).

* npm
* yarn
* pnpm

```
npm i @langchain/community langchain @langchain/openai @langchain/core

```

```
yarn add @langchain/community langchain @langchain/openai @langchain/core

```

```
pnpm add @langchain/community langchain @langchain/openai @langchain/core

```

## Instantiation[‚Äã](#instantiation "Direct link to Instantiation")

First, initialize your HNSWLib vector store with some documents that
contain metadata:

```
import { OpenAIEmbeddings } from "@langchain/openai";
import { HNSWLib } from "@langchain/community/vectorstores/hnswlib";
import { Document } from "@langchain/core/documents";
import type { AttributeInfo } from "langchain/chains/query_constructor";

/**
 * First, we create a bunch of documents. You can load your own documents here instead.
 * Each document has a pageContent and a metadata field. Make sure your metadata matches the AttributeInfo below.
 */
const docs = [
  new Document({
    pageContent:
      "A bunch of scientists bring back dinosaurs and mayhem breaks loose",
    metadata: { year: 1993, rating: 7.7, genre: "science fiction" },
  }),
  new Document({
    pageContent:
      "Leo DiCaprio gets lost in a dream within a dream within a dream within a ...",
    metadata: { year: 2010, director: "Christopher Nolan", rating: 8.2 },
  }),
  new Document({
    pageContent:
      "A psychologist / detective gets lost in a series of dreams within dreams within dreams and Inception reused the idea",
    metadata: { year: 2006, director: "Satoshi Kon", rating: 8.6 },
  }),
  new Document({
    pageContent:
      "A bunch of normal-sized women are supremely wholesome and some men pine after them",
    metadata: { year: 2019, director: "Greta Gerwig", rating: 8.3 },
  }),
  new Document({
    pageContent: "Toys come alive and have a blast doing so",
    metadata: { year: 1995, genre: "animated" },
  }),
  new Document({
    pageContent: "Three men walk into the Zone, three men walk out of the Zone",
    metadata: {
      year: 1979,
      director: "Andrei Tarkovsky",
      genre: "science fiction",
      rating: 9.9,
    },
  }),
];

/**
 * Next, we define the attributes we want to be able to query on.
 * in this case, we want to be able to query on the genre, year, director, rating, and length of the movie.
 * We also provide a description of each attribute and the type of the attribute.
 * This is used to generate the query prompts.
 */
const attributeInfo: AttributeInfo[] = [
  {
    name: "genre",
    description: "The genre of the movie",
    type: "string or array of strings",
  },
  {
    name: "year",
    description: "The year the movie was released",
    type: "number",
  },
  {
    name: "director",
    description: "The director of the movie",
    type: "string",
  },
  {
    name: "rating",
    description: "The rating of the movie (1-10)",
    type: "number",
  },
  {
    name: "length",
    description: "The length of the movie in minutes",
    type: "number",
  },
];

/**
 * Next, we instantiate a vector store. This is where we store the embeddings of the documents.
 * We also need to provide an embeddings object. This is used to embed the documents.
 */
const embeddings = new OpenAIEmbeddings();
const vectorStore = await HNSWLib.fromDocuments(docs, embeddings);

```

Now we can instantiate our retriever:

### Pick your chat model:

* Groq
* OpenAI
* Anthropic
* Google Gemini
* FireworksAI
* MistralAI
* VertexAI

#### Install dependencies

tip

See [this section for general instructions on installing integration packages](/docs/how_to/installation/#installing-integration-packages).

* npm
* yarn
* pnpm

```
npm i @langchain/groq

```

```
yarn add @langchain/groq

```

```
pnpm add @langchain/groq

```

#### Add environment variables

```
GROQ_API_KEY=your-api-key

```

#### Instantiate the model

```
import { ChatGroq } from "@langchain/groq";

const llm = new ChatGroq({
  model: "llama-3.3-70b-versatile",
  temperature: 0
});

```

#### Install dependencies

tip

See [this section for general instructions on installing integration packages](/docs/how_to/installation/#installing-integration-packages).

* npm
* yarn
* pnpm

```
npm i @langchain/openai

```

```
yarn add @langchain/openai

```

```
pnpm add @langchain/openai

```

#### Add environment variables

```
OPENAI_API_KEY=your-api-key

```

#### Instantiate the model

```
import { ChatOpenAI } from "@langchain/openai";

const llm = new ChatOpenAI({
  model: "gpt-4o-mini",
  temperature: 0
});

```

#### Install dependencies

tip

See [this section for general instructions on installing integration packages](/docs/how_to/installation/#installing-integration-packages).

* npm
* yarn
* pnpm

```
npm i @langchain/anthropic

```

```
yarn add @langchain/anthropic

```

```
pnpm add @langchain/anthropic

```

#### Add environment variables

```
ANTHROPIC_API_KEY=your-api-key

```

#### Instantiate the model

```
import { ChatAnthropic } from "@langchain/anthropic";

const llm = new ChatAnthropic({
  model: "claude-3-5-sonnet-20240620",
  temperature: 0
});

```

#### Install dependencies

tip

See [this section for general instructions on installing integration packages](/docs/how_to/installation/#installing-integration-packages).

* npm
* yarn
* pnpm

```
npm i @langchain/google-genai

```

```
yarn add @langchain/google-genai

```

```
pnpm add @langchain/google-genai

```

#### Add environment variables

```
GOOGLE_API_KEY=your-api-key

```

#### Instantiate the model

```
import { ChatGoogleGenerativeAI } from "@langchain/google-genai";

const llm = new ChatGoogleGenerativeAI({
  model: "gemini-2.0-flash",
  temperature: 0
});

```

#### Install dependencies

tip

See [this section for general instructions on installing integration packages](/docs/how_to/installation/#installing-integration-packages).

* npm
* yarn
* pnpm

```
npm i @langchain/community

```

```
yarn add @langchain/community

```

```
pnpm add @langchain/community

```

#### Add environment variables

```
FIREWORKS_API_KEY=your-api-key

```

#### Instantiate the model

```
import { ChatFireworks } from "@langchain/community/chat_models/fireworks";

const llm = new ChatFireworks({
  model: "accounts/fireworks/models/llama-v3p1-70b-instruct",
  temperature: 0
});

```

#### Install dependencies

tip

See [this section for general instructions on installing integration packages](/docs/how_to/installation/#installing-integration-packages).

* npm
* yarn
* pnpm

```
npm i @langchain/mistralai

```

```
yarn add @langchain/mistralai

```

```
pnpm add @langchain/mistralai

```

#### Add environment variables

```
MISTRAL_API_KEY=your-api-key

```

#### Instantiate the model

```
import { ChatMistralAI } from "@langchain/mistralai";

const llm = new ChatMistralAI({
  model: "mistral-large-latest",
  temperature: 0
});

```

#### Install dependencies

tip

See [this section for general instructions on installing integration packages](/docs/how_to/installation/#installing-integration-packages).

* npm
* yarn
* pnpm

```
npm i @langchain/google-vertexai

```

```
yarn add @langchain/google-vertexai

```

```
pnpm add @langchain/google-vertexai

```

#### Add environment variables

```
GOOGLE_APPLICATION_CREDENTIALS=credentials.json

```

#### Instantiate the model

```
import { ChatVertexAI } from "@langchain/google-vertexai";

const llm = new ChatVertexAI({
  model: "gemini-1.5-flash",
  temperature: 0
});

```

```
import { SelfQueryRetriever } from "langchain/retrievers/self_query";
import { FunctionalTranslator } from "@langchain/core/structured_query";

const selfQueryRetriever = SelfQueryRetriever.fromLLM({
  llm: llm,
  vectorStore: vectorStore,
  /** A short summary of what the document contents represent. */
  documentContents: "Brief summary of a movie",
  attributeInfo: attributeInfo,
  /**
   * We need to create a basic translator that translates the queries into a
   * filter format that the vector store can understand. We provide a basic translator
   * translator here, but you can create your own translator by extending BaseTranslator
   * abstract class. Note that the vector store needs to support filtering on the metadata
   * attributes you want to query on.
   */
  structuredQueryTranslator: new FunctionalTranslator(),
});

```

## Usage[‚Äã](#usage "Direct link to Usage")

Now, ask a question that requires some knowledge of the document‚Äôs
metadata to answer. You can see that the retriever will generate the
correct result:

```
await selfQueryRetriever.invoke("Which movies are rated higher than 8.5?");

```

```
[
  Document {
    pageContent: 'A psychologist / detective gets lost in a series of dreams within dreams within dreams and Inception reused the idea',
    metadata: { year: 2006, director: 'Satoshi Kon', rating: 8.6 },
    id: undefined
  },
  Document {
    pageContent: 'Three men walk into the Zone, three men walk out of the Zone',
    metadata: {
      year: 1979,
      director: 'Andrei Tarkovsky',
      genre: 'science fiction',
      rating: 9.9
    },
    id: undefined
  }
]

```

## Use within a chain[‚Äã](#use-within-a-chain "Direct link to Use within a chain")

Like other retrievers, HNSWLib self-query retrievers can be incorporated
into LLM applications via [chains](/docs/how_to/sequence/).

Note that because their returned answers can heavily depend on document
metadata, we format the retrieved documents differently to include that
information.

```
import { ChatPromptTemplate } from "@langchain/core/prompts";
import {
  RunnablePassthrough,
  RunnableSequence,
} from "@langchain/core/runnables";
import { StringOutputParser } from "@langchain/core/output_parsers";

import type { Document } from "@langchain/core/documents";

const prompt = ChatPromptTemplate.fromTemplate(`
Answer the question based only on the context provided.

Context: {context}

Question: {question}`);

const formatDocs = (docs: Document[]) => {
  return docs.map((doc) => JSON.stringify(doc)).join("\n\n");
};

// See https://js.langchain.com/docs/tutorials/rag
const ragChain = RunnableSequence.from([
  {
    context: selfQueryRetriever.pipe(formatDocs),
    question: new RunnablePassthrough(),
  },
  prompt,
  llm,
  new StringOutputParser(),
]);

```

```
await ragChain.invoke("Which movies are rated higher than 8.5?");

```

```
The movies rated higher than 8.5 are:

1. The movie directed by Satoshi Kon in 2006, which has a rating of 8.6.
2. The movie directed by Andrei Tarkovsky in 1979, which has a rating of 9.9.

```

## Default search params[‚Äã](#default-search-params "Direct link to Default search params")

You can also pass a `searchParams` field into the above method that
provides default filters applied in addition to any generated query. The
filter syntax is a predicate function:

```
const selfQueryRetrieverWithDefaults = SelfQueryRetriever.fromLLM({
  llm,
  vectorStore,
  documentContents: "Brief summary of a movie",
  attributeInfo,
  structuredQueryTranslator: new FunctionalTranslator(),
  searchParams: {
    filter: (doc: Document) => doc.metadata && doc.metadata.rating > 8.5,
    mergeFiltersOperator: "and",
  },
});

```

## API reference[‚Äã](#api-reference "Direct link to API reference")

For detailed documentation of all HNSWLib self-query retriever features
and configurations head to the [API
reference](https://api.js.langchain.com/classes/langchain.retrievers_self_query.SelfQueryRetriever.html).

---

#### Was this page helpful?

#### You can also leave detailed feedback [on GitHub](https://github.com/langchain-ai/langchainjs/issues/new?assignees=&labels=03+-+Documentation&projects=&template=documentation.yml&title=DOC%3A+%3CPlease+write+a+comprehensive+title+after+the+%27DOC%3A+%27+prefix%3E).

[Previous

Chroma](/docs/integrations/retrievers/self_query/chroma)[Next

In-memory](/docs/integrations/retrievers/self_query/memory)

* [Overview](#overview)
  + [Integration details](#integration-details)
* [Setup](#setup)
  + [Installation](#installation)
* [Instantiation](#instantiation)
* [Usage](#usage)
* [Use within a chain](#use-within-a-chain)
* [Default search params](#default-search-params)
* [API reference](#api-reference)

Community

* [Twitter](https://twitter.com/LangChainAI)

GitHub

* [Python](https://github.com/langchain-ai/langchain)
* [JS/TS](https://github.com/langchain-ai/langchainjs)

More

* [Homepage](https://langchain.com)
* [Blog](https://blog.langchain.dev)

Copyright ¬© 2025 LangChain, Inc.
[Skip to main content](#__docusaurus_skipToContent_fallback)

**Help us build the JS tools that power AI apps at companies like Replit, Uber, LinkedIn, GitLab, and more. [Join our team!](https://jobs.ashbyhq.com/langchain/05efa205-8560-43fd-bfcc-3f7697561cfb?utm_source=https%3A%2F%2Fjs.langchain.com%2F&utm_campaign=langchainjs_docs)**

[![ü¶úÔ∏èüîó Langchain](/img/brand/wordmark.png)![ü¶úÔ∏èüîó Langchain](/img/brand/wordmark-dark.png)](/)[Integrations](/docs/integrations/platforms/)[API Reference](https://v03.api.js.langchain.com)

More

* [People](/docs/people/)
* [Community](/docs/community)
* [Error reference](/docs/troubleshooting/errors)
* [External guides](/docs/additional_resources/tutorials)
* [Contributing](/docs/contributing)

v0.3

* [v0.3](/docs/introduction)
* [v0.2](https://js.langchain.com/v0.2/docs/introduction)
* [v0.1](https://js.langchain.com/v0.1/docs/get_started/introduction)

ü¶úüîó

* [LangSmith](https://smith.langchain.com)
* [LangSmith Docs](https://docs.smith.langchain.com)
* [LangChain Hub](https://smith.langchain.com/hub)
* [LangServe](https://github.com/langchain-ai/langserve)
* [Python Docs](https://python.langchain.com/)

[Chat](https://chatjs.langchain.com)

Search

* [Introduction](/docs/introduction)
* [Tutorials](/docs/tutorials/)

  + [Build a Question Answering application over a Graph Database](/docs/tutorials/graph)
  + [Tutorials](/docs/tutorials/)
  + [Build a simple LLM application with chat models and prompt templates](/docs/tutorials/llm_chain)
  + [Build a Chatbot](/docs/tutorials/chatbot)
  + [Build a Retrieval Augmented Generation (RAG) App: Part 2](/docs/tutorials/qa_chat_history)
  + [Build an Extraction Chain](/docs/tutorials/extraction)
  + [Tagging](/docs/tutorials/classification)
  + [Build a Retrieval Augmented Generation (RAG) App: Part 1](/docs/tutorials/rag)
  + [Build a semantic search engine](/docs/tutorials/retrievers)
  + [Build a Question/Answering system over SQL data](/docs/tutorials/sql_qa)
  + [Summarize Text](/docs/tutorials/summarization)
* [How-to guides](/docs/how_to/)

  + [How-to guides](/docs/how_to/)
  + [How to add memory to chatbots](/docs/how_to/chatbots_memory)
  + [How to use example selectors](/docs/how_to/example_selectors)
  + [Installation](/docs/how_to/installation)
  + [How to stream responses from an LLM](/docs/how_to/streaming_llm)
  + [How to stream chat model responses](/docs/how_to/chat_streaming)
  + [How to embed text data](/docs/how_to/embed_text)
  + [How to use few shot examples in chat models](/docs/how_to/few_shot_examples_chat)
  + [How to cache model responses](/docs/how_to/llm_caching)
  + [How to cache chat model responses](/docs/how_to/chat_model_caching)
  + [Richer outputs](/docs/how_to/custom_llm)
  + [How to use few shot examples](/docs/how_to/few_shot_examples)
  + [How to use output parsers to parse an LLM response into structured format](/docs/how_to/output_parser_structured)
  + [How to return structured data from a model](/docs/how_to/structured_output)
  + [How to add ad-hoc tool calling capability to LLMs and Chat Models](/docs/how_to/tools_prompting)
  + [Richer outputs](/docs/how_to/custom_chat)
  + [How to do per-user retrieval](/docs/how_to/qa_per_user)
  + [How to track token usage](/docs/how_to/chat_token_usage_tracking)
  + [How to track token usage](/docs/how_to/llm_token_usage_tracking)
  + [How to pass through arguments from one step to the next](/docs/how_to/passthrough)
  + [How to compose prompts together](/docs/how_to/prompts_composition)
  + [How to use legacy LangChain Agents (AgentExecutor)](/docs/how_to/agent_executor)
  + [How to add values to a chain's state](/docs/how_to/assign)
  + [How to attach runtime arguments to a Runnable](/docs/how_to/binding)
  + [How to cache embedding results](/docs/how_to/caching_embeddings)
  + [How to attach callbacks to a module](/docs/how_to/callbacks_attach)
  + [How to pass callbacks into a module constructor](/docs/how_to/callbacks_constructor)
  + [How to dispatch custom callback events](/docs/how_to/callbacks_custom_events)
  + [How to pass callbacks in at runtime](/docs/how_to/callbacks_runtime)
  + [How to await callbacks in serverless environments](/docs/how_to/callbacks_serverless)
  + [How to cancel execution](/docs/how_to/cancel_execution)
  + [How to split by character](/docs/how_to/character_text_splitter)
  + [How to init any model in one line](/docs/how_to/chat_models_universal_init)
  + [How to do retrieval](/docs/how_to/chatbots_retrieval)
  + [How to add tools to chatbots](/docs/how_to/chatbots_tools)
  + [How to split code](/docs/how_to/code_splitter)
  + [How to do retrieval with contextual compression](/docs/how_to/contextual_compression)
  + [How to convert Runnables to Tools](/docs/how_to/convert_runnable_to_tool)
  + [How to create custom callback handlers](/docs/how_to/custom_callbacks)
  + [How to write a custom retriever class](/docs/how_to/custom_retriever)
  + [How to create Tools](/docs/how_to/custom_tools)
  + [How to debug your LLM apps](/docs/how_to/debugging)
  + [How to load CSV data](/docs/how_to/document_loader_csv)
  + [How to write a custom document loader](/docs/how_to/document_loader_custom)
  + [How to load data from a directory](/docs/how_to/document_loader_directory)
  + [How to load HTML](/docs/how_to/document_loader_html)
  + [How to load Markdown](/docs/how_to/document_loader_markdown)
  + [How to load PDF files](/docs/how_to/document_loader_pdf)
  + [How to load JSON data](/docs/how_to/document_loaders_json)
  + [How to combine results from multiple retrievers](/docs/how_to/ensemble_retriever)
  + [How to select examples from a LangSmith dataset](/docs/how_to/example_selectors_langsmith)
  + [How to select examples by length](/docs/how_to/example_selectors_length_based)
  + [How to select examples by similarity](/docs/how_to/example_selectors_similarity)
  + [How to use reference examples](/docs/how_to/extraction_examples)
  + [How to handle long text](/docs/how_to/extraction_long_text)
  + [How to do extraction without using function calling](/docs/how_to/extraction_parse)
  + [Fallbacks](/docs/how_to/fallbacks)
  + [Few Shot Prompt Templates](/docs/how_to/few_shot)
  + [How to filter messages](/docs/how_to/filter_messages)
  + [How to run custom functions](/docs/how_to/functions)
  + [How to build an LLM generated UI](/docs/how_to/generative_ui)
  + [How to construct knowledge graphs](/docs/how_to/graph_constructing)
  + [How to map values to a database](/docs/how_to/graph_mapping)
  + [How to improve results with prompting](/docs/how_to/graph_prompting)
  + [How to add a semantic layer over the database](/docs/how_to/graph_semantic)
  + [How to reindex data to keep your vectorstore in-sync with the underlying data source](/docs/how_to/indexing)
  + [LangChain Expression Language Cheatsheet](/docs/how_to/lcel_cheatsheet)
  + [How to get log probabilities](/docs/how_to/logprobs)
  + [How to merge consecutive messages of the same type](/docs/how_to/merge_message_runs)
  + [How to add message history](/docs/how_to/message_history)
  + [How to migrate from legacy LangChain agents to LangGraph](/docs/how_to/migrate_agent)
  + [How to generate multiple embeddings per document](/docs/how_to/multi_vector)
  + [How to pass multimodal data directly to models](/docs/how_to/multimodal_inputs)
  + [How to use multimodal prompts](/docs/how_to/multimodal_prompts)
  + [How to generate multiple queries to retrieve data for](/docs/how_to/multiple_queries)
  + [How to try to fix errors in output parsing](/docs/how_to/output_parser_fixing)
  + [How to parse JSON output](/docs/how_to/output_parser_json)
  + [How to parse XML output](/docs/how_to/output_parser_xml)
  + [How to invoke runnables in parallel](/docs/how_to/parallel)
  + [How to retrieve the whole document for a chunk](/docs/how_to/parent_document_retriever)
  + [How to partially format prompt templates](/docs/how_to/prompts_partial)
  + [How to add chat history](/docs/how_to/qa_chat_history_how_to)
  + [How to return citations](/docs/how_to/qa_citations)
  + [How to return sources](/docs/how_to/qa_sources)
  + [How to stream from a question-answering chain](/docs/how_to/qa_streaming)
  + [How to construct filters](/docs/how_to/query_constructing_filters)
  + [How to add examples to the prompt](/docs/how_to/query_few_shot)
  + [How to deal with high cardinality categorical variables](/docs/how_to/query_high_cardinality)
  + [How to handle multiple queries](/docs/how_to/query_multiple_queries)
  + [How to handle multiple retrievers](/docs/how_to/query_multiple_retrievers)
  + [How to handle cases where no queries are generated](/docs/how_to/query_no_queries)
  + [How to recursively split text by characters](/docs/how_to/recursive_text_splitter)
  + [How to reduce retrieval latency](/docs/how_to/reduce_retrieval_latency)
  + [How to route execution within a chain](/docs/how_to/routing)
  + [How to do "self-querying" retrieval](/docs/how_to/self_query)
  + [How to chain runnables](/docs/how_to/sequence)
  + [How to split text by tokens](/docs/how_to/split_by_token)
  + [How to deal with large databases](/docs/how_to/sql_large_db)
  + [How to use prompting to improve results](/docs/how_to/sql_prompting)
  + [How to do query validation](/docs/how_to/sql_query_checking)
  + [How to stream agent data to the client](/docs/how_to/stream_agent_client)
  + [How to stream structured output to the client](/docs/how_to/stream_tool_client)
  + [How to stream](/docs/how_to/streaming)
  + [How to create a time-weighted retriever](/docs/how_to/time_weighted_vectorstore)
  + [How to return artifacts from a tool](/docs/how_to/tool_artifacts)
  + [How to use chat models to call tools](/docs/how_to/tool_calling)
  + [How to disable parallel tool calling](/docs/how_to/tool_calling_parallel)
  + [How to call tools with multimodal data](/docs/how_to/tool_calls_multimodal)
  + [How to force tool calling behavior](/docs/how_to/tool_choice)
  + [How to access the RunnableConfig from a tool](/docs/how_to/tool_configure)
  + [How to pass tool outputs to chat models](/docs/how_to/tool_results_pass_to_model)
  + [How to pass run time values to tools](/docs/how_to/tool_runtime)
  + [How to stream events from a tool](/docs/how_to/tool_stream_events)
  + [How to stream tool calls](/docs/how_to/tool_streaming)
  + [How to use LangChain tools](/docs/how_to/tools_builtin)
  + [How to handle tool errors](/docs/how_to/tools_error)
  + [How to use few-shot prompting with tool calling](/docs/how_to/tools_few_shot)
  + [How to trim messages](/docs/how_to/trim_messages)
  + [How use a vector store to retrieve data](/docs/how_to/vectorstore_retriever)
  + [How to create and query vector stores](/docs/how_to/vectorstores)
* [Conceptual Guide](/docs/concepts/)

  + [Agents](/docs/concepts/agents)
  + [Architecture](/docs/concepts/architecture)
  + [Callbacks](/docs/concepts/callbacks)
  + [Chat history](/docs/concepts/chat_history)
  + [Chat models](/docs/concepts/chat_models)
  + [Document loaders](/docs/concepts/document_loaders)
  + [Embedding models](/docs/concepts/embedding_models)
  + [Evaluation](/docs/concepts/evaluation)
  + [Example selectors](/docs/concepts/example_selectors)
  + [Few-shot prompting](/docs/concepts/few_shot_prompting)
  + [Conceptual guide](/docs/concepts/)
  + [Key-value stores](/docs/concepts/key_value_stores)
  + [LangChain Expression Language (LCEL)](/docs/concepts/lcel)
  + [Messages](/docs/concepts/messages)
  + [Multimodality](/docs/concepts/multimodality)
  + [Output parsers](/docs/concepts/output_parsers)
  + [Prompt Templates](/docs/concepts/prompt_templates)
  + [Retrieval augmented generation (rag)](/docs/concepts/rag)
  + [Retrieval](/docs/concepts/retrieval)
  + [Retrievers](/docs/concepts/retrievers)
  + [Runnable interface](/docs/concepts/runnables)
  + [Streaming](/docs/concepts/streaming)
  + [Structured outputs](/docs/concepts/structured_outputs)
  + [t](/docs/concepts/t)
  + [String-in, string-out llms](/docs/concepts/text_llms)
  + [Text splitters](/docs/concepts/text_splitters)
  + [Tokens](/docs/concepts/tokens)
  + [Tool calling](/docs/concepts/tool_calling)
  + [Tools](/docs/concepts/tools)
  + [Tracing](/docs/concepts/tracing)
  + [Vector stores](/docs/concepts/vectorstores)
  + [Why LangChain?](/docs/concepts/why_langchain)
* Ecosystem

  + [ü¶úüõ†Ô∏è LangSmith](https://docs.smith.langchain.com/)
  + [ü¶úüï∏Ô∏è LangGraph.js](https://langchain-ai.github.io/langgraphjs/)
* Versions

  + [v0.3](/docs/versions/v0_3/)
  + [v0.2](/docs/versions/v0_2/)
  + [Migrating from v0.0 memory](/docs/versions/migrating_memory/)

    - [How to migrate to LangGraph memory](/docs/versions/migrating_memory/)
    - [How to use BaseChatMessageHistory with LangGraph](/docs/versions/migrating_memory/chat_history)
    - [Migrating off ConversationTokenBufferMemory](/docs/versions/migrating_memory/conversation_buffer_window_memory)
    - [Migrating off ConversationSummaryMemory or ConversationSummaryBufferMemory](/docs/versions/migrating_memory/conversation_summary_memory)
  + [Release Policy](/docs/versions/release_policy)
* [Security](/docs/security)

* Conceptual Guide

On this page

# Conceptual guide

This guide provides explanations of the key concepts behind the LangChain framework and AI applications more broadly.

We recommend that you go through at least one of the [Tutorials](/docs/tutorials) before diving into the conceptual guide. This will provide practical context that will make it easier to understand the concepts discussed here.

The conceptual guide does not cover step-by-step instructions or specific implementation examples ‚Äî those are found in the [How-to guides](/docs/how_to/) and [Tutorials](/docs/tutorials). For detailed reference material, please see the [API reference](https://api.js.langchain.com/).

## High level[‚Äã](#high-level "Direct link to High level")

* **[Why LangChain?](/docs/concepts/why_langchain)**: Overview of the value that LangChain provides.
* **[Architecture](/docs/concepts/architecture)**: How packages are organized in the LangChain ecosystem.

## Concepts[‚Äã](#concepts "Direct link to Concepts")

* **[Chat models](/docs/concepts/chat_models)**: LLMs exposed via a chat API that process sequences of messages as input and output a message.
* **[Messages](/docs/concepts/messages)**: The unit of communication in chat models, used to represent model input and output.
* **[Chat history](/docs/concepts/chat_history)**: A conversation represented as a sequence of messages, alternating between user messages and model responses.
* **[Tools](/docs/concepts/tools)**: A function with an associated schema defining the function's name, description, and the arguments it accepts.
* **[Tool calling](/docs/concepts/tool_calling)**: A type of chat model API that accepts tool schemas, along with messages, as input and returns invocations of those tools as part of the output message.
* **[Structured output](/docs/concepts/structured_outputs)**: A technique to make a chat model respond in a structured format, such as JSON that matches a given schema.
* **[Memory](https://langchain-ai.github.io/langgraphjs/concepts/memory/)**: Information about a conversation that is persisted so that it can be used in future conversations.
* **[Multimodality](/docs/concepts/multimodality)**: The ability to work with data that comes in different forms, such as text, audio, images, and video.
* **[Runnable interface](/docs/concepts/runnables)**: The base abstraction that many LangChain components and the LangChain Expression Language are built on.
* **[Streaming](/docs/concepts/streaming)**: LangChain streaming APIs for surfacing results as they are generated.
* **[LangChain Expression Language (LCEL)](/docs/concepts/lcel)**: A syntax for orchestrating LangChain components. Most useful for simpler applications.
* **[Document loaders](/docs/concepts/document_loaders)**: Load a source as a list of documents.
* **[Retrieval](/docs/concepts/retrieval)**: Information retrieval systems can retrieve structured or unstructured data from a datasource in response to a query.
* **[Text splitters](/docs/concepts/text_splitters)**: Split long text into smaller chunks that can be individually indexed to enable granular retrieval.
* **[Embedding models](/docs/concepts/embedding_models)**: Models that represent data such as text or images in a vector space.
* **[Vector stores](/docs/concepts/vectorstores)**: Storage of and efficient search over vectors and associated metadata.
* **[Retriever](/docs/concepts/retrievers)**: A component that returns relevant documents from a knowledge base in response to a query.
* **[Retrieval Augmented Generation (RAG)](/docs/concepts/rag)**: A technique that enhances language models by combining them with external knowledge bases.
* **[Agents](/docs/concepts/agents)**: Use a [language model](/docs/concepts/chat_models) to choose a sequence of actions to take. Agents can interact with external resources via [tool](/docs/concepts/tools).
* **[Prompt templates](/docs/concepts/prompt_templates)**: Component for factoring out the static parts of a model "prompt" (usually a sequence of messages). Useful for serializing, versioning, and reusing these static parts.
* **[Output parsers](/docs/concepts/output_parsers)**: Responsible for taking the output of a model and transforming it into a more suitable format for downstream tasks. Output parsers were primarily useful prior to the general availability of [tool calling](/docs/concepts/tool_calling) and [structured outputs](/docs/concepts/structured_outputs).
* **[Few-shot prompting](/docs/concepts/few_shot_prompting)**: A technique for improving model performance by providing a few examples of the task to perform in the prompt.
* **[Example selectors](/docs/concepts/example_selectors)**: Used to select the most relevant examples from a dataset based on a given input. Example selectors are used in few-shot prompting to select examples for a prompt.
* **[Callbacks](/docs/concepts/callbacks)**: Callbacks enable the execution of custom auxiliary code in built-in components. Callbacks are used to stream outputs from LLMs in LangChain, trace the intermediate steps of an application, and more.
* **[Tracing](/docs/concepts/tracing)**: The process of recording the steps that an application takes to go from input to output. Tracing is essential for debugging and diagnosing issues in complex applications.
* **[Evaluation](/docs/concepts/evaluation)**: The process of assessing the performance and effectiveness of AI applications. This involves testing the model's responses against a set of predefined criteria or benchmarks to ensure it meets the desired quality standards and fulfills the intended purpose. This process is vital for building reliable applications.

## Glossary[‚Äã](#glossary "Direct link to Glossary")

* **[AIMessageChunk](/docs/concepts/messages#aimessagechunk)**: A partial response from an AI message. Used when streaming responses from a chat model.
* **[AIMessage](/docs/concepts/messages#aimessage)**: Represents a complete response from an AI model.
* **[StructuredTool](https://api.js.langchain.com/classes/_langchain_core.tools.StructuredTool.html)**: The base class for all tools in LangChain.
* **[batch](/docs/concepts/runnables)**: Use to execute a runnable with batch inputs a Runnable.
* **[bindTools](/docs/concepts/tool_calling/#tool-binding)**: Allows models to interact with tools.
* **[Caching](/docs/concepts/chat_models#caching)**: Storing results to avoid redundant calls to a chat model.
* **[Context window](/docs/concepts/chat_models#context-window)**: The maximum size of input a chat model can process.
* **[Conversation patterns](/docs/concepts/chat_history#conversation-patterns)**: Common patterns in chat interactions.
* **[Document](https://api.js.langchain.com/classes/_langchain_core.documents.Document.html)**: LangChain's representation of a document.
* **[Embedding models](/docs/concepts/embedding_models)**: Models that generate vector embeddings for various data types.
* **[HumanMessage](/docs/concepts/messages#humanmessage)**: Represents a message from a human user.
* **[input and output types](/docs/concepts/runnables#input-and-output-types)**: Types used for input and output in Runnables.
* **[Integration packages](/docs/concepts/architecture#integration-packages)**: Third-party packages that integrate with LangChain.
* **[invoke](/docs/concepts/runnables)**: A standard method to invoke a Runnable.
* **[JSON mode](/docs/concepts/structured_outputs#json-mode)**: Returning responses in JSON format.
* **[@langchain/community](/docs/concepts/architecture#langchaincommunity)**: Community-driven components for LangChain.
* **[@langchain/core](/docs/concepts/architecture#langchaincore)**: Core langchain package. Includes base interfaces and in-memory implementations.
* **[langchain](/docs/concepts/architecture#langchain)**: A package for higher level components (e.g., some pre-built chains).
* **[@langchain/langgraph](/docs/concepts/architecture#langchainlanggraph)**: Powerful orchestration layer for LangChain. Use to build complex pipelines and workflows.
* **[Managing chat history](/docs/concepts/chat_history#managing-chat-history)**: Techniques to maintain and manage the chat history.
* **[OpenAI format](/docs/concepts/messages#openai-format)**: OpenAI's message format for chat models.
* **[Propagation of RunnableConfig](/docs/concepts/runnables#propagation-of-runnableconfig)**: Propagating configuration through Runnables.
* **[RemoveMessage](/docs/concepts/messages#removemessage)**: An abstraction used to remove a message from chat history, used primarily in LangGraph.
* **[role](/docs/concepts/messages#role)**: Represents the role (e.g., user, assistant) of a chat message.
* **[RunnableConfig](/docs/concepts/runnables#runnableconfig)**: Use to pass run time information to Runnables (e.g., `runName`, `runId`, `tags`, `metadata`, `maxConcurrency`, `recursionLimit`, `configurable`).
* **[Standard parameters for chat models](/docs/concepts/chat_models#standard-parameters)**: Parameters such as API key, `temperature`, and `maxTokens`,
* **[stream](/docs/concepts/streaming)**: Use to stream output from a Runnable or a graph.
* **[Tokenization](/docs/concepts/tokens#how-tokens-work-in-language-models)**: The process of converting data into tokens and vice versa.
* **[Tokens](/docs/concepts/tokens)**: The basic unit that a language model reads, processes, and generates under the hood.
* **[Tool artifacts](/docs/concepts/tools#tool-artifacts)**: Add artifacts to the output of a tool that will not be sent to the model, but will be available for downstream processing.
* **[Tool binding](/docs/concepts/tool_calling#tool-binding)**: Binding tools to models.
* **[`tool`](/docs/concepts/tools)**: Function for creating tools in LangChain.
* **[Toolkits](/docs/concepts/tools#toolkits)**: A collection of tools that can be used together.
* **[ToolMessage](/docs/concepts/messages#toolmessage)**: Represents a message that contains the results of a tool execution.
* **[Vector stores](/docs/concepts/vectorstores)**: Datastores specialized for storing and efficiently searching vector embeddings.
* **[withStructuredOutput](/docs/concepts/structured_outputs/#structured-output-method)**: A helper method for chat models that natively support [tool calling](/docs/concepts/tool_calling) to get structured output matching a given schema specified via Zod, JSON schema or a function.

---

#### Was this page helpful?

#### You can also leave detailed feedback [on GitHub](https://github.com/langchain-ai/langchainjs/issues/new?assignees=&labels=03+-+Documentation&projects=&template=documentation.yml&title=DOC%3A+%3CPlease+write+a+comprehensive+title+after+the+%27DOC%3A+%27+prefix%3E).

[Previous

How to create and query vector stores](/docs/how_to/vectorstores)[Next

Agents](/docs/concepts/agents)

* [High level](#high-level)
* [Concepts](#concepts)
* [Glossary](#glossary)

Community

* [Twitter](https://twitter.com/LangChainAI)

GitHub

* [Python](https://github.com/langchain-ai/langchain)
* [JS/TS](https://github.com/langchain-ai/langchainjs)

More

* [Homepage](https://langchain.com)
* [Blog](https://blog.langchain.dev)

Copyright ¬© 2025 LangChain, Inc.